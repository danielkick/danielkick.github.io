{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a53a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re, os\n",
    "from datetime import datetime\n",
    "\n",
    "def read_json(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        dat = json.load(f)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bfba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4facc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daveiscool',\n",
       " 'canvases.json',\n",
       " 'integration_logs.json',\n",
       " 'data_analysis',\n",
       " '.DS_Store',\n",
       " 'interesting-reads',\n",
       " 'general',\n",
       " 'mpg_reads',\n",
       " 'schulzlab_science',\n",
       " 'channels.json',\n",
       " 'users.json',\n",
       " 'better_code',\n",
       " 'model_systems',\n",
       " 'professional-development',\n",
       " 'ephys',\n",
       " 'tacos',\n",
       " 'random',\n",
       " 'stgmeeting2020']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.listdir('/Users/danielkick/Downloads/Schulz Lab Slack export Jul 19 2016 - Apr 9 2024/')\n",
    "os.listdir('./Schulz Lab Slack export Jul 19 2016 - Apr 9 2024/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b13386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc = '/Users/danielkick/Downloads/Schulz Lab Slack export Jul 19 2016 - Apr 9 2024/better_code/'\n",
    "# loc_assets = '/Users/danielkick/Downloads/better_code_assets/'\n",
    "\n",
    "loc = './Schulz Lab Slack export Jul 19 2016 - Apr 9 2024/better_code/'\n",
    "loc_assets = './better_code_assets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3380e8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-04-01.json',\n",
       " '2020-04-10.json',\n",
       " '2020-04-20.json',\n",
       " '2023-04-06.json',\n",
       " '2023-05-23.json',\n",
       " '2023-07-12.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = os.listdir(loc)\n",
    "posts.sort()\n",
    "posts[0:3]+posts[-4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec39fce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6a7ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [read_json(loc+e) for e in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad45d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f59d87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = posts[1]\n",
    "post = [e for e in post if 'subtype' not in e.keys()]\n",
    "len(post)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9decb07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5768d238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a49829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_entry(entry = post[0]):\n",
    "    out = []\n",
    "\n",
    "    ts = datetime.fromtimestamp(int(entry['ts'].split('.')[0])).date()\n",
    "    ts = f'{ts.year}-{ts.month}-{ts.day}'\n",
    "    ts = f'<span style=\"color: #33b2ff\">{ts}</span>'\n",
    "    \n",
    "    out += [ts]\n",
    "\n",
    "    if 'user_profile' in entry.keys():\n",
    "        name = entry['user_profile']['display_name']\n",
    "        name = f'<span style=\"color: #33b2ff\">{name}</span>'\n",
    "        out += [name]\n",
    "\n",
    "    text = entry['text']\n",
    "    out += [text]\n",
    "\n",
    "    if 'files' in entry.keys():\n",
    "        for i in range(len(entry['files'])):\n",
    "            out += [f'![{entry[\"files\"][i][\"title\"]}]({entry[\"files\"][i][\"name\"]})']\n",
    "\n",
    "    out = '\\n'.join(out)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af66539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_post(post):\n",
    "    post = [e for e in post if 'subtype' not in e.keys()]\n",
    "    # print(len(post))\n",
    "    post_out = ['\\n---\\n']+[format_entry(entry = e) for e in post]\n",
    "    return post_out\n",
    "\n",
    "formatted_posts = [format_post(post = e) for e in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee6d41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_posts = sum(formatted_posts, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc803f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_w_name_image = [e for e in range(len(formatted_posts)) if re.search('image.png', formatted_posts[e])]\n",
    "# idx_w_name_image = [e for e in range(len(formatted_posts)) if re.finditer('image.png', formatted_posts[e])]\n",
    "\n",
    "# len(idx_w_name_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e7a3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len([e for e in os.listdir(loc_assets) if re.match('^image.*', e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12bc0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [e for e in re.finditer('a', 'a a a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a3a7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_posts[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2d683f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect = re.search('image.png', formatted_posts[7])\n",
    "# detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db870e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b834c656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n---\\n',\n",
       " '<span style=\"color: #33b2ff\">2020-4-10</span>\\nIf you\\'re iteratively making plots, resampling, or doing another task that would have your reach for a for loop or `lapply()` use `furrr::future_map()` instead. `furrr` gives parallel processing ready versions of tidyverse\\'s `purrr` functions (e.g. `map()`,  `walk()`). It\\'s easy to install the dependencies and takes a lot of the headache out of parallel processing.\\n![cpu_use_1.PNG](cpu_use_1.PNG)\\n![cpu_use_0.PNG](cpu_use_0.PNG)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f85a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f37dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd88768",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'formatted_posts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m frontmatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m---\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mtitle: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetter_code\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mformat: html\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124meditor: source\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m---\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m write_text \u001b[38;5;241m=\u001b[39m frontmatter\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mformatted_posts\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'formatted_posts' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "frontmatter = \"\"\"---\n",
    "title: \"better_code\"\n",
    "format: html\n",
    "editor: source\n",
    "---\"\"\"\n",
    "\n",
    "write_text = frontmatter+'\\n'+'\\n\\n'.join(formatted_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix code blocks\n",
    "write_text = write_text.replace('```', '\\n```\\n')\n",
    "write_text = write_text.replace('&gt;', '>')\n",
    "write_text = write_text.replace('&lt;', '<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86168115",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_text = write_text.split('```')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8342e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_text = ''.join([write_text[i]+'``` r' if (i % 2) == 0 else write_text[i]+'```' for i in range(len(write_text))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34fe965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0db4e82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./better_code_assets/'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8e7bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loc_assets+'temp.qmd', 'w') as f:\n",
    "    f.write(write_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97b73129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace image file names with 'image (x).png' for all but the first entry\n",
    "\n",
    "tmp = write_text.split('[image.png](image.png)')\n",
    "\n",
    "tmp = [\n",
    "    [tmp[i], f'[image.png](image.png)'] if i == 0 else \n",
    "    [tmp[i], f'[image ({i}).png](image%20({i}).png)'] \n",
    "    for i in range(len(tmp))]\n",
    "\n",
    "tmp = sum(tmp, [])[0:-1]\n",
    "\n",
    "tmp = ''.join(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c702b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loc_assets+'temp.qmd', 'w') as f:\n",
    "    f.write(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb861dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bae4478e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# %20(43)\n",
    "\n",
    "\n",
    "# if no name use previous name?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "993976ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# posts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dac568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3820b89f",
   "metadata": {},
   "source": [
    "## Remade version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "942ed59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "mkdir(path = './output/')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fcc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = './Schulz Lab Slack export Jul 19 2016 - Apr 9 2024/better_code/'\n",
    "loc_assets = './better_code_assets/'\n",
    "\n",
    "# loc = './Schulz Lab Slack export Jul 19 2016 - Apr 9 2024/data_analysis/'\n",
    "# loc_assets = './data_analysis_assets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3332a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = '2023-07-12.json' \n",
    "entries = [read_json(loc+e) for e in os.listdir(loc)]\n",
    "entries = [[ee for ee in e if 'subtype' not in ee.keys()]\n",
    "            for e in entries]\n",
    "entries = [ee[0] for ee in entries if ee != []]\n",
    "\n",
    "\n",
    "\n",
    "def parse_entry(entry):\n",
    "    ts = datetime.fromtimestamp(int(entry['ts'].split('.')[0])).date()\n",
    "    ts = f'{ts.year}-{ts.month}-{ts.day}'\n",
    "\n",
    "    # name = entry['user_profile']['display_name']\n",
    "    name = entry['user']\n",
    "\n",
    "    text = entry['text']\n",
    "\n",
    "    files = []\n",
    "    if 'files' in entry.keys():\n",
    "        files = [f'![{entry[\"files\"][i][\"title\"]}]({entry[\"files\"][i][\"name\"]})' \n",
    "                for i in range(len(entry['files']))]\n",
    "\n",
    "    return (ts, name, text, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352a0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6bfc9d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2022-5-26',\n",
       " 'U1T7R897Y',\n",
       " 'Late to the party but here’s my two cents:\\n• The final plots are good. I personally use a point for the median but it works either way. \\n• Nudging the statistics on the x axis can help with readability. To <@U028ZEAHA6S>’s point, raincloud plots are a nice way to incorporate a density/violin. Tufte style boxplots are another nice option (for maximizing info/ink). This doesn’t work so well as well with beeswarms.\\n',\n",
       " [])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_entry(entry=entries[1])\n",
    "# Is this me? U1T7R897Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756639e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for json_entry in entries:\n",
    "\n",
    "    ts, name, text, files = parse_entry(entry=json_entry)\n",
    "\n",
    "    quarto_text = '\\n'.join([\n",
    "    '---',\n",
    "    f'title: \"Placeholder\"',\n",
    "    f'author: \"{name}\"',\n",
    "    f'date: \"{ts}\"',\n",
    "    'image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"',\n",
    "    'categories: ',\n",
    "    '  - code',\n",
    "    '  - beginner',\n",
    "    '  - r',\n",
    "    'draft: false',\n",
    "    'editor: ',\n",
    "    '  markdown: ',\n",
    "    '    wrap: 72',\n",
    "    '---',\n",
    "    '',\n",
    "    text,\n",
    "    '', \n",
    "    (lambda x: '' if x == [] else '\\n'.join(x))(files)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737c6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ['\\n'.join([\n",
    "    '---',\n",
    "    f'author: \"{name}\"',\n",
    "    f'date: \"{ts}\"',\n",
    "    '---',\n",
    "    '',\n",
    "    text,\n",
    "    '', \n",
    "    (lambda x: '' if x == [] else '\\n'.join(x))(files)\n",
    "    ]) for ts, name, text, files in [parse_entry(entry=json_entry) for json_entry in entries]]\n",
    "\n",
    "all_text = '\\n'.join(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72f13cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_text = \"\"\"\n",
    "2020-4-1\n",
    "Daniel\n",
    "You can keep your working `Rmd` easier to navigate and less buggy by 1) packaging code into functions and 2) adding them to a companion `R` file. Load your functions with `source()` in the same block you load your libraries with a relative path, full path, or ideally with `here()`.\n",
    "\n",
    "``` r\n",
    "library(here)\n",
    "source(here(\"R\", \"02MoniterGapJunction.R\")) #here's output is effectively ../R/02MoniterGapJunction.R\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-4-10\n",
    "If you're iteratively making plots, resampling, or doing another task that would have your reach for a for loop or `lapply()` use `furrr::future_map()` instead. `furrr` gives parallel processing ready versions of tidyverse's `purrr` functions (e.g. `map()`,  `walk()`). It's easy to install the dependencies and takes a lot of the headache out of parallel processing.\n",
    "![cpu_use_1.PNG](cpu_use_1.PNG)\n",
    "![cpu_use_0.PNG](cpu_use_0.PNG)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-4-20\n",
    "Daniel\n",
    "If you're running low on memory, you can retain specific objects by running this:\n",
    "\n",
    "``` r\n",
    " \n",
    "# get rid of everything\n",
    "rm(list=ls())\n",
    "\n",
    "# get rid of everything except specific objects and all loaded functions\n",
    "rm(list = \n",
    "   ls()[!(ls() %in% c(\n",
    "   # objects\n",
    "   c(\"data1\", \"data2\", \"bool1\", \"list1\"), \n",
    "   # functions\n",
    "   lsf.str())\n",
    "   ) ])\n",
    "```\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "2020-4-20\n",
    "Daniel\n",
    "`lsf.str()` returns a character string of the functions you've written. This doesnt' include functions from libraries so it may not be needed if you have used `source()` to pull your custom functions from `/R/`.\n",
    "\n",
    "2020-4-20\n",
    "If you're tempted to use `rm(list = ls())` consider restarting your r session (`ctrl+shift+F10` on windows). Overreliance on `rm(list = ls())` is poor form and the Rstudio devs will know and find you.\n",
    "![image.png](image.png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-4-21\n",
    "Daniel\n",
    "If you're applying the same theme to all your graphs, set it globally instead e.g. `theme_set(ggplot2::theme_minimal())`.  If you have a lot of custom changes to your theme, throw those into a function and set that to the global theme.\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-5-4\n",
    "If you're on windows, `installr` should allow you to copy over the libraries from previous versions.\n",
    "![image (1).png](image%20(1).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-5-6\n",
    "Don't get suckered when converting factors! Numeric data can be assigned to a factor type which will throw a wrench in a plot or analysis (1/3)\n",
    "![image (2).png](image%20(2).png)\n",
    "\n",
    "2020-5-6\n",
    "A knee jerk reaction would be to convert it to a numeric with `as.numeric()`. That doesn't work either.  (2/3)\n",
    "![image (3).png](image%20(3).png)\n",
    "\n",
    "2020-5-6\n",
    "However if you use `as.numeric(as.character())` then it works. That's because factors are ordinal and named so if you convert the type to character first to ensure R is working with the factor names instead of the ranks. (3/3)\n",
    "![image (4).png](image%20(4).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-5-11\n",
    "Daniel\n",
    "Need a quick base `R` syntax lookup? Check out <https://learnxinyminutes.com/docs/r/> .  There are even examples with `lm()` and `glm()`.\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "2020-5-11\n",
    "Daniel\n",
    "tldr: `tidyverse` function variants take slightly different input. Testing out a variant or two can save you a lot of debugging time.\n",
    "\n",
    "In `tidyverse` watch out for inconsistencies in function versions. There are variants of common functions (e.g. `mutate()` `mutate_all()` `mutate_at()`) don't necessarily behave the same way (or how you would expect).\n",
    "\n",
    "Here, I was applying an operation to a grouped df where each `Experiment` contains several `FileName`s with multiple observations in each.  To keep everything reusable I'm using `exp` instead of `Experiment` to select the right col.\n",
    "\n",
    "``` r\n",
    "> exp = \"Experiment\"\n",
    "> rec = \"FileName\"\n",
    "\n",
    "> df %>%\n",
    "+     dplyr::select(\n",
    "+       exp, rec, r11, r12\n",
    "+     )\n",
    "# A tibble: 564 x 4\n",
    "   Experiment FileName           r11   r12\n",
    "   <chr>      <chr>            <dbl> <dbl>\n",
    " 1 190808a    190808a_0020.abf  5.06 0.150\n",
    " 2 190808a    190808a_0020.abf  5.13 0.160\n",
    " 3 190808a    190808a_0020.abf  5.11 0.122\n",
    " 4 190808a    190808a_0020.abf  2.49 0.152\n",
    " 5 190808a    190808a_0020.abf  2.49 0.195\n",
    "# ... with 559 more rows\n",
    "```\n",
    "\n",
    "As soon as we do the same thing with `group_by()` we don't get the right column even though `select()` didn't have an issue with `exp`.\n",
    "\n",
    "``` r\n",
    "> df %>%\n",
    "+     dplyr::select(\n",
    "+       exp, rec, r11, r12\n",
    "+     ) %>%\n",
    "+     group_by(exp, rec)\n",
    "Error: Column `exp` is unknown\n",
    "```\n",
    "\n",
    "So we can try explicitly selecting the columns we want as groupings.\n",
    "\n",
    "``` r\n",
    ">     df %>%\n",
    "+     dplyr::select(\n",
    "+       exp, rec, r11, r12\n",
    "+     ) %>%\n",
    "+     group_by(vars(exp, rec))\n",
    "Error: Column `vars(exp, rec)` must be length 564 (the number of rows) or one, not 2\n",
    "```\n",
    "\n",
    "No dice there. `vars()` is designed to work with the `_at` variants so we can try that.  _et voilà!_\n",
    "\n",
    "``` r\n",
    "> df %>%\n",
    "+     dplyr::select(\n",
    "+       exp, rec, r11, r12\n",
    "+     ) %>%\n",
    "+     group_by_at(vars(exp, rec))\n",
    "\n",
    "# A tibble: 564 x 4\n",
    "# Groups:   Experiment, FileName [69]\n",
    "   Experiment FileName           r11   r12\n",
    "   <chr>      <chr>            <dbl> <dbl>\n",
    " 1 190808a    190808a_0020.abf  5.06 0.150\n",
    " 2 190808a    190808a_0020.abf  5.13 0.160\n",
    " 3 190808a    190808a_0020.abf  5.11 0.122\n",
    " 4 190808a    190808a_0020.abf  2.49 0.152\n",
    " 5 190808a    190808a_0020.abf  2.49 0.195\n",
    "# ... with 559 more rows\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-5-12\n",
    "Daniel\n",
    "Save `R` objects as rds. These could be works in progress or items that take a while to generate (e.g. re-sampled results). This gives the utility of saving a work space without the dangers.\n",
    "\n",
    "``` r\n",
    "library(here)\n",
    "save(df, file = here(\"data\", \"df.rds\"))\n",
    "# df is now saved at ./data/df.rds\n",
    "\n",
    "load(here(\"data\", \"df.rds\"))\n",
    "# df is now loaded from ./data/df.rds as df\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-5-15\n",
    "Daniel\n",
    "If you're using git for version control, don't forget about the `.gitignore` file. Anything large and static (like .abfs) or procedurally generated (e.g. plots) you can toss in the `.gitignore` and you'll not see it when you commit.\n",
    "\n",
    "I have tabular data that lives in `./inst/extdata/` is processed by a script and then saved as a .rds in `./data/`.  Here's my `.gitignore`.\n",
    "\n",
    "\n",
    "``` r\n",
    ".Rproj.user\n",
    ".Rhistory\n",
    ".RData\n",
    ".Ruserdata\n",
    "# Don't track ABFs -- large and static\n",
    "*.abf\n",
    "# Don't track files that are generated from the scripts\n",
    "/data/*\n",
    "```\n",
    "\n",
    "For more check out <https://git-scm.com/docs/gitignore>\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-5-19\n",
    "Daniel\n",
    "If you need to include greek letters or special characters in a plot use `annotate()` instead of `geom_text()`. On my machine it preforms a *lot* faster.\n",
    "\n",
    "\n",
    "``` r\n",
    "# 57.62977 secs\n",
    "geom_text(aes(x = 15, y = 25, label = \"phi~22.5\"), parse=TRUE)\n",
    "# 1.988642 secs\n",
    "annotate(\"text\", x = 15, y = 25, parse = TRUE, label = as.character(expression(paste(phi, \" 22.5\"))))\n",
    "```\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "2020-5-19\n",
    "Use `geom_rect()` with the min/max set to `-Inf` and `Inf` to add a pleasant shading to your facets.\n",
    "\n",
    "For example by passing it a data frame with the faceting variables and a column to use for the color (green if positive, red if negative) we can make facets behave like cells in  a heatmap!\n",
    "\n",
    "``` r\n",
    "# > tp2\n",
    "# # A tibble: 23 x 5\n",
    "#    Condition   Trace             Time  Change StimId\n",
    "#    <fct>       <chr>             <chr>  <dbl> <chr> \n",
    "#  1 PS.0.orig   170623b_0007.abf  60         1 a     \n",
    "#  2 PS.45.orig  170825a_0008.abf  60        -1 c     \n",
    "\n",
    "ggplot(df)+\n",
    "  geom_rect(data = tp2, aes(fill = Change),xmin = -Inf,xmax = Inf, ymin = -Inf,ymax = Inf,alpha = 0.3) +\n",
    "  geom_hline(yintercept = 0, color = \"cornflowerblue\")+\n",
    "  geom_pointline(aes(x = Time, y = rc, group = Experiment), shape = 1, color = \"black\")+\n",
    "  ylim(-2, 3.5)+\n",
    "  scale_fill_gradientn(colors = c(\"Red\", \"Grey\", \"Green\"))+\n",
    "  theme_base()+\n",
    "  theme(legend.position = \"\")\n",
    "```\n",
    "\n",
    "![image (5).png](image%20(5).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "2020-5-26\n",
    "Handy trick:\n",
    "Write your test results into a summary csv. Then while writing you can insert a link to the cell value for a result into your .doc. After that, changing post hoc corrections, re-sampling iterations, or data QC just requires you to re-run your code and let word refresh all the links.\n",
    "\n",
    "You can also do this from excel, but you'll have to update the formula for the cell used instead.\n",
    "\n",
    "<#C010AS4PSUX|data_analysis>\n",
    "![AutoUpdateStats.gif](AutoUpdateStats.gif)\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "2020-6-4\n",
    "If you're looking at linear relationships, give this code a spin. It'll automatically flag outliers based on 1.5*IQR and show you the fit with and without the outliers.  Since the output is a ggplot, you and add to it or tweak the aesthetics of the output (see example below). If anyone has a favorite outlier detection method and ends up modifying this, please post it here so we can see it! <@U0103JSQYLB> <@U010CH4JLKE> <@U010M1M3N9E>\n",
    "\n",
    "Here's the function.\n",
    "\n",
    "``` r\n",
    "scatter_w_wo_outliers <- function(temp = filter(M, Time == \"Baseline\"),\n",
    "                                  X = \"bkkca\", \n",
    "                                  Y = \"Ihtk.0\"){\n",
    "  \n",
    "  # flag outliers based on 1.5xIQR from median\n",
    "  X_low  <- median(temp[[X]], na.rm = T) - (1.5 * IQR(temp[[X]], na.rm = T))\n",
    "  X_high <- median(temp[[X]], na.rm = T) + (1.5 * IQR(temp[[X]], na.rm = T))\n",
    "  Y_low  <- median(temp[[Y]], na.rm = T) - (1.5 * IQR(temp[[Y]], na.rm = T))\n",
    "  Y_high <- median(temp[[Y]], na.rm = T) + (1.5 * IQR(temp[[Y]], na.rm = T))\n",
    "  \n",
    "  X_pass <- (temp[[X]] > X_low) * (temp[[X]] < X_high)\n",
    "  Y_pass <- (temp[[Y]] > Y_low) * (temp[[Y]] < Y_high)\n",
    "\n",
    "  temp$flag <- ifelse((X_pass * Y_pass) == 1, T, F)\n",
    "  \n",
    "  \n",
    "  # Duplicate so we have dataset 1, 2 (introduces duplicates)\n",
    "  temp <- rbind(temp[temp$flag == T, ], mutate(temp, flag = F))\n",
    "  \n",
    "  formula1 <- y ~ x\n",
    "  \n",
    "  plt <- ggplot(temp, aes_string(X, Y, color = \"flag\"))+\n",
    "    geom_smooth(data = temp, method = lm, se = F, fullrange = T)+\n",
    "    geom_point(data = temp)+\n",
    "    geom_point(data = temp, color = \"black\", shape = 1)+\n",
    "    geom_point(data = temp[temp$flag, ])+\n",
    "    ggpmisc::stat_poly_eq(aes(label =  paste(stat(eq.label), \"*\\\" with \\\"*\", \n",
    "                                             stat(rr.label), \"*\\\", \\\"*\", \n",
    "                                             stat(f.value.label), \"*\\\", and \\\"*\",\n",
    "                                             stat(p.value.label), \"*\\\".\\\"\",\n",
    "                                             sep = \"\")),\n",
    "                          formula = formula1, parse = TRUE, size = 4)+\n",
    "    \n",
    "    scale_color_manual(values = c(\"darkgray\", \"black\"))+\n",
    "    theme_bw()+\n",
    "    theme(legend.position = \"\")\n",
    "  \n",
    "  return(plt)\n",
    "}\n",
    "```\n",
    "\n",
    "Here's a reproducible example. We're creating a Simpson's paradox by giving the \"outliers\" a negative slope and the real data a positive slope. I've added a red line showing the true relationship.\n",
    "\n",
    "``` r\n",
    "set.seed(45645684)\n",
    "df <- data.frame(x = rnorm(30, mean = 10, sd = 4),\n",
    "                 noise = runif(30, min = -2, max = 2),\n",
    "                 y = NA,\n",
    "                 is_outlier = rbinom(30, 1, prob = 0.2))\n",
    "\n",
    "\n",
    "df$y <- ifelse(df$is_outlier, \n",
    "               -5*df$x+df$noise,\n",
    "               2*df$x+df$noise)\n",
    "\n",
    "scatter_w_wo_outliers(temp = df,\n",
    "                      X = \"x\",\n",
    "                      Y = \"y\")+\n",
    "  geom_abline(slope = 2, intercept = 0, color = \"firebrick\")\n",
    "```\n",
    "\n",
    "![image (7).png](image%20(7).png)\n",
    "\n",
    "\n",
    "2020-6-4\n",
    "Daniel\n",
    "Here's a related utility function. For a given column it'll return a logical vector where outliers are `FALSE`.\n",
    "\n",
    "``` r\n",
    "w_in_x_iqr <- function(col_in, multiplier = 1.5){\n",
    "  col_in <- as.vector(col_in)\n",
    "  \n",
    "  X_low  <- median(col_in, na.rm = T) - (multiplier * IQR(col_in, na.rm = T))\n",
    "  X_high <- median(col_in, na.rm = T) + (multiplier * IQR(col_in, na.rm = T))\n",
    "  X_pass <- (col_in > X_low) * (col_in < X_high)\n",
    "  \n",
    "  return(as.logical(X_pass))\n",
    "}\n",
    "```\n",
    "\n",
    "e.g.\n",
    "\n",
    "``` r\n",
    "> mutate(M, ex = w_in_x_iqr(bkkca)) %>% select(bkkca, ex) %>% arrange(bkkca) %>% tail()\n",
    "\n",
    "#  A tibble: 6 x 2\n",
    "#   bkkca ex   \n",
    "#   <dbl> <lgl>\n",
    "# 1 3056. TRUE \n",
    "# 2 3222. TRUE \n",
    "# 3 3255. TRUE   # Within bounds\n",
    "# 4 3552. FALSE  # Outside bounds \n",
    "# 5 3817. FALSE\n",
    "# 6 6740. FALSE\n",
    "```\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-6-5\n",
    "ggplot's, `element_text()` comes with a color argument. Why does that matter? It doesn't just accept atomics, you can hand it a _vector_! This effectively gives one access to conditional formatting. This works on `ggplot2_3.3.0` but \"vectorized input to `element_text()` is not officially supported\" so YMMV with newer versions.\n",
    "\n",
    "Here's an example I think it makes an otherwise unbearable figure a little more so without requiring duplicated labels.\n",
    "\n",
    "One thing to be aware of is the ordering of a character/ factor may differ between a data.frame and the plot. In the visualized example, I had `mRNA` as type character instead of factor so it got alphabetized when it was plotted rather than by the order appearing in the data.frame.\n",
    "![image (8).png](image%20(8).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-6-12\n",
    "Daniel\n",
    "Trying something new here-- \"Function Friday\". If you've written a function you're rather pleased with, used one in a creative way, or know one that you think deserves it's time in the sun please share it here.\n",
    "\n",
    "I'll start. Y'all should be using `unlist()`. `unlist` is a crazy handy function when you pair it with the `purrr` library. It'll take a list and try to give you a vector. Strictly speaking it's probably best to be using `map_dbl()` or `map_chr()` instead but let's not worry about that at the moment.\n",
    "\n",
    "Why do I love `unlist` so much? Because `unlist(map( ))` gives you a flexible, effective way to iterate (that is parallel friendly with minor changes).\n",
    "\n",
    "Here's an example: I have a bunch of traces in a folder and I need to know if there are any experiments that didn't copy. Additionally, I'd like to know what kind of data is in the file. I _could_ look through them one by one, but that's no fun. Thankfully, R has functions that perform similarly to shell functions. (More on these some other time.)\n",
    "\n",
    "So we start by defining a data.frame with all file names and their sizes. Note that calling `unlist(map())` _inside_ `data.frame()` lets us do a lot work very quickly. We find all the files, get information about each one, and then selectively return the size.\n",
    "\n",
    "``` r\n",
    "traces_dir <- \"C:/Users/Daniel/Documents/Trace_Holding\"\n",
    "\n",
    "files_df <- data.frame(files = list.files(traces_dir),\n",
    "                       bytes = unlist(map(list.files(traces_dir), \n",
    "                                          function(abf){ <http://file.info|file.info>(paste0(traces_dir, \"/\",abf))$size })))\n",
    "\n",
    "#              files    bytes\n",
    "# 1 190808a_0000.abf 15006208 <- long gap free recording\n",
    "# 2 190808a_0001.abf 15006208\n",
    "# 3 190808a_0002.abf 15006208\n",
    "```\n",
    "\n",
    "The experiment is embedded in the file name for each. Once again , with a little help from `unlist` we can split the file names into a list of list (i.e. `\"190808a_0000.abf\"` becomes `[[1]] [[1]] \"190808a\" [[2]] \"0000.abf\"` select only the first part and populate a new column.\n",
    "\n",
    "``` r\n",
    "files_df$Experiment <- unlist(transpose(str_split(files_df$files, pattern = \"_\"))[[1]])\n",
    "```\n",
    "\n",
    "\n",
    "Okay, now we can make use of this. I've defined a data.frame for metadata about the experiments.\n",
    "\n",
    "``` r\n",
    "file_groups\n",
    "#    Experiment       Group\n",
    "# 1      190924    Baseline\n",
    "# ... \n",
    "# 19     190918     Delayed\n",
    "```\n",
    "\n",
    "We can join these data frames and apply a little `tidyverse` magic to see what experiments are missing (we could also compare the sets of experiments directly).\n",
    "\n",
    "``` r\n",
    "full_join(file_groups, files_df) %>% \n",
    "  filter(<http://is.na|is.na>(files)) %>% \n",
    "  group_by(Group, Experiment) %>% \n",
    "  tally()\n",
    "\n",
    "#  Experiments that didn't transfer:\n",
    "\n",
    "#   Group       Experiment     n\n",
    "# 1 Baseline    190924         1\n",
    "# 2 Baseline    190924a        1\n",
    "# ...\n",
    "```\n",
    "\n",
    "We can repeat the same strategy to programattically look at the protocol types (e.g. based on file size or channel number via `<http://file.info|file.info>` | `readABF()`). Moral of the story, you should so stop `apply`ing yourself and give `unlist` and `purrr` functions a try.\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-6-15\n",
    "Daniel\n",
    "If you run into a situation where you're using a ton of memory (e.g. manipulating transcriptomic data, resampling, or working with electrophysiology traces)  use `rm()` to selectively get rid off objects in the environment. A useful pattern is to write out large objects you'll need in the future, remove them, and then read them back in when you need them. This is usually not important, but when it is, it is.\n",
    "\n",
    "A side note -- unlike listing items where the function matching the unix command acts on the environment and a new command acts on the files system (`ls()` and `list.files()`) the functions for removing items don't follow this logic. `rm()` acts on objects in your environment whereas `unlink()` acts on system files.\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-6-25\n",
    "Daniel\n",
    "The `tictoc` library has convenience functions for timing code.  Here’s the basic usage relative to timing with base R.\n",
    "\n",
    "``` r\n",
    "library(tictoc)\n",
    "tic()\n",
    "# code here\n",
    "toc()\n",
    "\n",
    "tic <- Sys.time()\n",
    "# code here\n",
    "toc <- Sys.time()\n",
    "print(toc - tic)\n",
    "```\n",
    "\n",
    "Where this library excels is when you want to time multiple parts of your code. Each `tic` pushes the time onto a stack and each `toc` pops the most recent time from said stack. That means you don’t have to worry about assigning several timing variables even if you want to time nested code.\n",
    "\n",
    "``` r\n",
    "tic()\n",
    "# stack is 1 deep\n",
    "for (i in 1:10) {\n",
    "     tic()\n",
    "     # stack is now 2 deep\n",
    "     for (j in 1:10){\n",
    "          tic()\n",
    "          # stack is now 3 deep\n",
    "          toc()\n",
    "     }\n",
    "     toc()\n",
    "}\n",
    "toc()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-7-28\n",
    "In tidyverse you can use `.` to reference the current dataframe. This is really useful for plotting. For example, I'd like to plot channels In7 and In12 in that order but by default In12 will come first. We could save an intermediate dataframe and re-level the factors, but by referencing the dataframe piped into mutate we can skip this step.\n",
    "\n",
    "\n",
    "``` r\n",
    "temp %>% # temp is a down-sampled ephys recording\n",
    "  ungroup() %>% \n",
    "  gather(key, value, c(\"In7\", \"In12\")) %>% \n",
    "  mutate(key = factor(.$key, levels = c(\"In7\", \"In12\"))) %>%      # Note that if you have groupings, you'll need to get rid of them or supply a column of the same length as the group. \n",
    "  ggplot(aes(Time, value, color = key, group = interaction(key, Sweep)))+\n",
    "  geom_path()\n",
    "```\n",
    "\n",
    "\n",
    "![image (11).png](image%20(11).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-7-30\n",
    "If you want to make future you more positively disposed to present you, then organize your work with `R` packages, save your custom functions in the `/R/` directory. The function `roxygen2::roxygenise()` will documentation comments for your functions into help pages. For example running `roxygenise()` with the below function saved produces the attached help page accessible via `?shrug`.\n",
    "\n",
    "\n",
    "``` r\n",
    "#' @title Print Shrug\n",
    "#' @description This function prints a shrug emoji a specified number of times, provided the input value is a numeric greater than zero.\n",
    "#' @param n how many shrugs should be printed\n",
    "#' @author Daniel Kick (\\email{daniel.r.kick@@gmail.com})\n",
    "#' @export\n",
    "#' @examples\n",
    "#' shrug(5)\n",
    "\n",
    "shrug <- function(n = 1, ...){\n",
    "  if (is.numeric(n) & n>0){\n",
    "    for (i in seq(1, n)){\n",
    "        cat(\"¯\\\\_(ツ)_/¯\\n\")\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "![image (12).png](image%20(12).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "2020-8-22\n",
    "Be mindful of your data types. Sometimes `T == 1 == 1.0` (logical, int, double) but assuming these are equivalent can get you into trouble. For example, in these animations, the only difference is the data is coerced to logicals or integers.\n",
    "![conway_bool.gif](conway_bool.gif)\n",
    "![conway_int.gif](conway_int.gif)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-9-19\n",
    "Daniel\n",
    "If you're working on data that takes a long time to process, consider adding a the following to your analysis.\n",
    "\n",
    "``` r\n",
    "save.image(file='myEnvironment.RData')\n",
    "load('myEnvironment.RData')\n",
    "```\n",
    "\n",
    "This will let you reload your environment. One can also by default save your environment when closing Rstudio but that may make it easy to reference objects that no longer are generated in the document itself thereby speeding software rot.\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "2020-11-4\n",
    "Daniel\n",
    "<@U010CH4JLKE> As an example to show how accessible this is, here's bit of code that resamples an anova and computes an empirical p value.\n",
    "\n",
    "`temp` is a dataframe containing the data\n",
    "`Condition` is a column with exactly that\n",
    "`temp_col` is the name of a dependent variable. It's a string to make this easy to reuse.\n",
    "if you haven't used `map` before it's basically a for loop that returns a list. When the output get's passed into `unlist` it becomes an array.\n",
    "\n",
    "\n",
    "``` r\n",
    "temp_shuffle <- temp\n",
    "resample_array <- map(1:1000, function(i){\n",
    "     temp_shuffle$Condition <- sample(temp_shuffle$Condition, replace = F)\n",
    "     fm <- lm(as.formula(paste0(temp_col, \" ~ Condition\")), data = temp_shuffle)      \n",
    "     return(car::Anova(fm)[1,3])\n",
    "}) %>% unlist()\n",
    "ep <- mean(resample_array >= car::Anova(fm)[1,3])\n",
    "```\n",
    "\n",
    "The down side is that it takes orders of magnitude more time to run because you're running the same code hundreds or thousands of times. This is only a problem if you need crazy high precision or have a really complex/hard to fit model. For reference using the code above took about ~2 seconds/dv for 1000 iterations on my machine.\n",
    "\n",
    "2020-11-4\n",
    "Daniel\n",
    "<@U0103JSQYLB>  A handy pattern is to use map to summarize data and then bind it.\n",
    "\n",
    "``` r\n",
    "map_res <- map(names(M)[names(M) != \"Sample\"], function(i){\n",
    "  res <- shapiro.test(M[[i]])\n",
    "\n",
    "  return(\n",
    "    list(\n",
    "    mrna = i,\n",
    "    p = res$p.value\n",
    "    )\n",
    "  )\n",
    "})\n",
    "\n",
    "shapiro_res <- do.call(rbind, map_res)\n",
    "```\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-11-20\n",
    "Daniel\n",
    "For all you classics fiends out there, R has a convenience function just for you! (As long as your numbers aren't too big)\n",
    "\n",
    "``` r\n",
    "> as.numeric(as.roman(\"MCXXIII\"))\n",
    "[1] 1123\n",
    "> as.roman(1123)\n",
    "[1] MCXXIII\n",
    "> as.roman(11234)\n",
    "[1] <NA>\n",
    "```\n",
    "\n",
    "<https://twitter.com/geokaramanis/status/1327286201443905538|source>\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-12-7\n",
    "Daniel\n",
    "Get ready to celebrate in the streets: native pipes and terse lambdas are coming to R!\n",
    "\n",
    "> *R* now provides a simple native pipe syntax `|>` as well as a shorthand notation for creating functions, e.g. `\\(x) x + 1` is parsed as `function(x) x + 1`. \n",
    "<https://cran.r-project.org/doc/manuals/r-devel/NEWS.html>\n",
    "\n",
    "\n",
    "2020-12-7\n",
    "David Schulz\n",
    "I am a little torn though.  I LOVE me a terse lambda.\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "2020-12-9\n",
    "Check out `DiagrammeR` (or mermaid) if you need clean easy flow diagrams. I find they're not to hard to make and _even easier_ to forget that you've made them.\n",
    "\n",
    "\n",
    "``` r\n",
    "DiagrammeR::grViz(\"digraph {\n",
    "graph [layout = dot]\n",
    "\n",
    "# define the global styles of the nodes. We can override these in box if we wish\n",
    "node [shape = circle, style = filled, fillcolor = LightSteelBlue]\n",
    "\n",
    "data1 [label = 'Input', shape = folder, fillcolor = Beige]\n",
    "\n",
    "glmnet [label = 'Lasso \\nRegression', shape = box, fillcolor = Linen]\n",
    "mnnet [label = 'Mulitnomial \\nNeural \\nNetwork', shape = box, fillcolor = Linen]\n",
    "nnet [label = 'Neural \\nNetwork', shape = box, fillcolor = Linen]\n",
    "knn [label = 'k-Nearest \\nNeighbor', shape = box, fillcolor = Linen]\n",
    "ranger [label = 'Random \\nForest', shape = box, fillcolor = Linen]\n",
    "svml [label = 'SVM \\nLinear', shape = box, fillcolor = Linen]\n",
    "svmr [label = 'SVM \\nRadial', shape = box, fillcolor = Linen]\n",
    "\n",
    "data2 [label = '5-fold CV \\nAccuracy', shape = folder, fillcolor = Beige]\n",
    "\n",
    "# edge definitions with the node IDs\n",
    "data1 -> {glmnet mnnet nnet knn ranger svml svmr} -> data2\n",
    "{alpha lambda} -> glmnet\n",
    "decay -> mnnet\n",
    "{size decay} -> nnet\n",
    "k -> knn\n",
    "{mtry splitrule minNodeSize} -> ranger\n",
    "cost -> svml\n",
    "sigma -> svmr\n",
    "}\")\n",
    "```\n",
    "\n",
    "![image (15).png](image%20(15).png)\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "2020-12-18\n",
    "Daniel\n",
    "I just ran into the same issue <@U010N31RYMV> described after updating R on OSX —  none of the libraries are associated with the new version. I tested and abandoned directly copying the libraries over in favor programmatic reinstallation. The downside to this is that it’s slower. The upside is that if you just copy them, R will ask you to update the packages anyway.\n",
    "\n",
    "This won’t work for libraries that aren’t on CRAN but drastically reduces the number of libraries you’re installing by hand. In my case this took care of all but about 3% of the libraries I had installed for 3.6.\n",
    "\n",
    "\n",
    "``` r\n",
    "all_packages <- list.files(\"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/\")\n",
    "installed_packages <- list.files(\"/Library/Frameworks/R.framework/Versions/4.0/Resources/library/\")\n",
    "all_packages <- all_packages[!(all_packages %in% installed_packages)]\n",
    "\n",
    "options(install.packages.compile.from.source = \"always\")\n",
    "\n",
    "for (package in all_packages){\n",
    "  try(install.packages(package))\n",
    "}\n",
    "\n",
    "options(install.packages.compile.from.source = \"interactive\")\n",
    "```\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2020-12-22\n",
    "You can set ggplot's font using the `theme` function. Particularly if combined with functions from `ggthemes` or `ggsci` you can get very pleasing visualizations quickly. Beyond accessing fonts already on your system you can import and fonts with minimal hassle.\n",
    "\n",
    "e.g. to get the font <https://fonts.google.com/specimen/Metal+Mania?sidebar.open=true&amp;selection.family=JetBrains+Mono:wght@100&amp;query=metal|Metal Mania> :metal: ready to use one might run:\n",
    "\n",
    "``` r\n",
    "library(showtext)\n",
    "font_add_google(name = \"Metal Mania\", family = \"Metal+Mania\")\n",
    "```\n",
    "\n",
    "\n",
    "``` r\n",
    "library(palmerpenguins)\n",
    "library(tidyverse)\n",
    "library(ggthemes)\n",
    "library(patchwork) # for adding together plots at the end\n",
    "library(extrafont)\n",
    "# font_import()) # <--- run this once\n",
    "loadfonts(device = \"win\", quiet = TRUE) # <--- run this once per session\n",
    "# extrafont::fonts() # see fonts that are available\n",
    "\n",
    "plt1 <- palmerpenguins::penguins %>%\n",
    "  filter(!<http://is.na|is.na>(sex)) %>%\n",
    "  mutate(sex = case_when(sex == \"male\" ~ \"m\",\n",
    "                         sex == \"female\" ~ \"f\")) %>% \n",
    "  ggplot(aes(sex, body_mass_g, fill = species, group = interaction(species, sex)))+\n",
    "  geom_boxplot()+\n",
    "  ggthemes::scale_fill_colorblind()+\n",
    "  ggthemes::theme_clean()+\n",
    "  theme(legend.position = \"\")+\n",
    "  facet_grid(.~species)+\n",
    "  labs(title = \"Default\")\n",
    "\n",
    "plt2 <- plt1+\n",
    "  theme(text = element_text(family = \"Consolas\"))+\n",
    "  labs(title = \"Consolas\")\n",
    "\n",
    "plt3 <- plt1+\n",
    "  theme(text = element_text(family = \"Garamond\"))+\n",
    "  labs(title = \"Garamond\")\n",
    "\n",
    "plt1 + plt2 + plt3\n",
    "```\n",
    "\n",
    "\n",
    "![image (17).png](image%20(17).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2021-2-2\n",
    "Anyone run into issues with `corrplot::corrplot()`  cutting off the title?\n",
    "![image (18).png](image%20(18).png)\n",
    "\n",
    "\n",
    "\n",
    "2021-2-2\n",
    "`ggcorrplot` makes okay plots with ggplot2's logic. Not as clean as the above but it'll work with `patchwork`  and `cowplot` . Unfortunately, `scale_colour_stepsn`  doesn't override the  scaling.\n",
    "\n",
    "``` r\n",
    "library(ggcorrplot)\n",
    "\n",
    "p.mat <- cor_pmat(cor_df)\n",
    "ggcorrplot(cor(cor_df, use = \"pairwise.complete.obs\"), \n",
    "           p.mat = p.mat,\n",
    "           insig = \"blank\",\n",
    "           type = \"upper\",\n",
    "           outline.col = \"white\",\n",
    "           colors = RColorBrewer::brewer.pal(n = 9, name = \"PuOr\")[c(1,5,9)]\n",
    "           )+\n",
    "  labs(title = \"Brian_AP_Delayed\")\n",
    "```\n",
    "\n",
    "\n",
    "![image (19).png](image%20(19).png)\n",
    "\n",
    "2021-2-2\n",
    "`ggcorrplot` appears to call internal functions which makes modifying it quickly impractical (one would probably be best forking the package and modifying that). I think I have a workaround that gets the same binning behavior:\n",
    "\n",
    "After the significance matrix (`p.mat`) is generated overwrite the correlation matrix with the middle value of each desired bin.\n",
    "\n",
    "``` r\n",
    "          bkkca      cav1      cav2\n",
    "bkkca 1.0000000 0.3452702 0.5603564\n",
    "cav1  0.3452702 1.0000000 0.7880727\n",
    "cav2  0.5603564 0.7880727 1.0000000\n",
    "> # bin the correlations so there are fewer colors used in the figure\n",
    "> cor_bins <- seq(-1, 1, length.out = 9)\n",
    "> for (i in 1:(length(cor_bins)-1)){\n",
    "+   test[test > cor_bins[i] &amp; test < cor_bins[i+1]] <- ((cor_bins[i] + cor_bins[i+1])/2)\n",
    "+ }\n",
    "> test\n",
    "      bkkca  cav1  cav2\n",
    "bkkca 1.000 0.375 0.625\n",
    "cav1  0.375 1.000 0.875\n",
    "cav2  0.625 0.875 1.000\n",
    "```\n",
    "\n",
    "Here this makes very slight changes to the plot. (legend dropped to not imply a continuous fill)\n",
    "![image (20).png](image%20(20).png)\n",
    "\n",
    "2021-2-2\n",
    "Last update, this is harder to read up will use the more extreme value to get closer to `corrplot`\n",
    "\n",
    "\n",
    "``` r\n",
    "test <- seq(-1, 1, length.out = 5)+.0000001\n",
    "test\n",
    "#-0.9999999 -0.4999999  0.0000001  0.5000001  1.0000001\n",
    "for (i in 1:(length(cor_bins)-1)){\n",
    "  # test[test > cor_bins[i] &amp; test < cor_bins[i+1]] <- (cor_bins[i] + cor_bins[i+1])\n",
    "  test[test > cor_bins[i] &amp; test < cor_bins[i+1]] <-   cor_bins[c(i, (i+1))[which.max(abs(cor_bins[i:(i+1)]))]]\n",
    "}\n",
    "test\n",
    "#-1.00 -0.50  0.25  0.75  1.00\n",
    "```\n",
    "\n",
    "\n",
    "![image (21).png](image%20(21).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2021-2-3\n",
    "Daniel\n",
    "<@U0103JSQYLB> and I just talked through how one might compare two sets of p values. We're thinking about the following approach and wanted to see if anyone can see a flaw in this approach or has other ideas.\n",
    "\n",
    "Setup:\n",
    "You have two replicates of an experiment (`r1, r2`). In each experiment you measured three mRNAs (_`a, b, c`_) in control and treatment (`c, t`). You want to know if the same trends in `r1` show up in `r2` but there is a batch effect that will prevent comparing them directly (e.g. you can't run a t test on `r1 _a_ c` and `r2 _a_ c` )\n",
    "\n",
    "Proposed Solution:\n",
    "1. Compare each mRNA within a replicate and note the sign of change and if the p value reached a pre-determined cutoff\n",
    "\n",
    "``` r\n",
    "rep  |mrna |sign |pval |sig  |\n",
    "r1   | a   | -   |0.04 |1    |\n",
    "r1   | b   | +   |0.10 |0    |\n",
    "...  |     |     |     |     |\n",
    "r2   | c   | -   |0.02 |1    |\n",
    "```\n",
    "\n",
    "2. Multiply the sign by the significance code so that -1 = \"significant decrease\", 0 = \"no significant change\", +1 = \"significant increase\"\n",
    "\n",
    "``` r\n",
    "rep  |mrna |sign |pval |sig  |sxp  |\n",
    "r1   | a   | -   |0.04 |1    |+1   |\n",
    "r1   | b   | +   |0.10 |0    |0    |\n",
    "...  |     |     |     |     |     |\n",
    "r2   | c   | -   |0.02 |0    |-1   |\n",
    "```\n",
    "\n",
    "3. Reshape these as two vectors and treat them as categorical data. Then compare the \"assignment\" between these two lists using a jaccard index as if we were comparing an assignment from clustering against reality.\n",
    "\n",
    "``` r\n",
    "r1 <- as.character(c(1, 0, 0))\n",
    "r2 <- as.character(c(0, 0, -1))\n",
    "jaccard(r1, r2)\n",
    "```\n",
    "\n",
    "4. Use resampling to find an empirical p value for this observed jaccard index.\n",
    "\n",
    "Does that seem reasonable? Is there another way you would go about it?\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2021-2-10\n",
    "Here's an implementation for two sets of correlations. Here we bin the correlations into 5 bins use a jaccard index to assess whether the bin assignments are the same for both datasets (Brian's and mine). To confirm that the measured jaccard index (0.23) isn't anything to write home about we can generate  an empirical p value (ep = 0.13).\n",
    "\n",
    "\n",
    "``` r\n",
    "# cor_comp_df\n",
    "#\n",
    "#    Source Time     x     y        Corr\n",
    "#    <fct>  <fct>    <chr> <chr>   <dbl>\n",
    "#  1 Brian  Baseline bkkca cav1    0.441\n",
    "#  2 Brian  Baseline bkkca cav2    0.476\n",
    "#  3 Brian  Baseline bkkca inx1    0.435\n",
    "#  4 Brian  Baseline bkkca inx2    0.159\n",
    "#  5 Brian  Baseline bkkca inx3   -0.174\n",
    "#  6 Brian  Baseline bkkca inx4   -0.167\n",
    "\n",
    "n_bins <- 5\n",
    "\n",
    "temp <- cor_comp_df %>% \n",
    "  mutate(Bins = cut(Corr, breaks = seq(-1, 1, length.out = n_bins))) %>% \n",
    "  select(-Corr) %>% \n",
    "  pivot_wider(names_from = \"Source\", values_from = \"Bins\")\n",
    "\n",
    "# temp\n",
    "#\n",
    "#   Time     x     y     Brian    Daniel  \n",
    "#   <fct>    <chr> <chr> <fct>    <fct>   \n",
    "# 1 Baseline bkkca cav1  (0,0.5]  (0,0.5] \n",
    "# 2 Baseline bkkca cav2  (0,0.5]  (0,0.5] \n",
    "# 3 Baseline bkkca inx1  (0,0.5]  (0.5,1] \n",
    "# 4 Baseline bkkca inx2  (0,0.5]  (0.5,1] \n",
    "# 5 Baseline bkkca inx3  (-0.5,0] (0.5,1] \n",
    "# 6 Baseline bkkca inx4  (-0.5,0] (-0.5,0]\n",
    "\n",
    "\n",
    "library('clusteval')\n",
    "obs_jaccard <- cluster_similarity(temp$Brian, temp$Daniel, similarity=\"jaccard\")  \n",
    "\n",
    "# 0.2304234\n",
    "\n",
    "null_jaccard <- map(1:10000, function(i){\n",
    "  cluster_similarity(sample(temp$Brian, replace = F), \n",
    "                     temp$Daniel, similarity=\"jaccard\")\n",
    "  }) %>% \n",
    "  unlist()\n",
    "\n",
    "\n",
    "temp <- with(density(null_jaccard), data.frame(x, y))\n",
    "temp <- temp %>% mutate(xmax = max(x),\n",
    "                obs = obs_jaccard)\n",
    "\n",
    "ggplot(data = temp, aes(x = x, y = y))+\n",
    "  geom_line()+\n",
    "  geom_vline(xintercept = obs_jaccard)+\n",
    "  geom_ribbon(data = temp[temp$x > temp$obs, ], \n",
    "              aes(xmin = obs, xmax = xmax, ymin = 0, ymax = y))+\n",
    "  labs(subtitle = paste(\"empirical p=\", as.character(mean(null_jaccard >= obs_jaccard))))\n",
    "```\n",
    "\n",
    "\n",
    "![image (22).png](image%20(22).png)\n",
    "\n",
    "2021-2-10\n",
    "It's worth generating an empirical p value for each comparison you're making. For example here I'm comparing the results of an experiment replicate. Each dependent variable is assigned a group based on if one would conclude it there was a difference (0 or 1) between groups and the sign of that difference (+ or -). Seeing a Jaccard index of 0.61 (out of 1) we might conclude we replicated most of the findings. _However,_ the empirical p value is 1 because most of the comparisons were non-significant in both groups resulting in a high floor for the index.\n",
    "![image (23).png](image%20(23).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "\n",
    "2021-2-21\n",
    "I think I have a solution to get decent enough dendrograms without fussing with base graphics.\n",
    "\n",
    "The overview of my workaround is to cluster with `pvclust`, extract `$hclust` , plot it as a dendrogram, coerce into a ggplot.  This makes it easy enough to replicate the functionality of the `colored_bars()`  function by making additional plots.  The function below makes a few plots in addition to the dendrogram. If you end up working with base graphics anyway, `dendextend` is still worth a look.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "``` r\n",
    "# needed \n",
    "library(pvclust)\n",
    "library(tidyverse)\n",
    "library(dendextend) # for color_labels\n",
    "library(ggnewscale) # to accommodate two fill scales \n",
    "\n",
    "# recommended\n",
    "# install.packages(\"palmerpenguins\")\n",
    "library(palmerpenguins)\n",
    "library(patchwork)\n",
    "library(scales) # for overiding scientific notation on dendrogram y axis \n",
    "\n",
    "# Make a demo dataset\n",
    "tux <- select(palmerpenguins::penguins, \n",
    "              species,\n",
    "              bill_length_mm, bill_depth_mm, \n",
    "              flipper_length_mm, body_mass_g) \n",
    "\n",
    "tux <- tux[complete.cases(tux), ]\n",
    "\n",
    "set.seed(54646)\n",
    "tux <- tux[sample(1:nrow(tux), 30), ] # for faster demo clustering\n",
    "\n",
    "# Example use\n",
    "o <- \n",
    "  mk_hclust_plts(\n",
    "    df = mutate(tux, uid = paste(seq(1, nrow(tux)), species, sep = \"-\")),\n",
    "    cluster_by = c(\"bill_length_mm\", \"bill_depth_mm\", \n",
    "                   \"flipper_length_mm\", \"body_mass_g\"),\n",
    "    uid_col = \"uid\",\n",
    "    n_clusters = 3,\n",
    "    true_groups = \"species\",\n",
    "    true_colors = RColorBrewer::brewer.pal(3, \"Set2\"),\n",
    "    cluster_colors = RColorBrewer::brewer.pal(3, \"Set1\") \n",
    "  )\n",
    "\n",
    "\n",
    "# Patchwork to arrange the output plots\n",
    "(o$dendrogram_both+\n",
    "    scale_y_continuous(limits = c(-.0001, 0.00022), labels = scales::comma)\n",
    ")/ \n",
    "  (o$group_compare_tile+\n",
    "     # lims(y =  c(2, -2))+ # y axis can be flipped like so\n",
    "     theme(legend.position = \"\")\n",
    "  ) / \n",
    "  (o$heatmap_raw + theme(legend.position = \"right\")) / \n",
    "  (o$heatmap_z + theme(legend.position = \"right\")) + \n",
    "  patchwork::plot_layout(heights = c(5, .3, 1.25, 1.25))\n",
    "\n",
    "\n",
    "# example 2\n",
    "\n",
    "# o <- \n",
    "# mk_hclust_plts(\n",
    "#   df = mutate(iris, uid = paste(seq(1, nrow(iris)), Species, sep = \"-\")),\n",
    "#   cluster_by = c(\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"),\n",
    "#   uid_col = \"uid\",\n",
    "#   n_clusters = 3,\n",
    "#   true_groups = \"Species\",\n",
    "#   true_colors = RColorBrewer::brewer.pal(3, \"Set2\"),\n",
    "#   cluster_colors = RColorBrewer::brewer.pal(3, \"Set1\") \n",
    "# )\n",
    "```\n",
    "\n",
    "ps, it's worth checking your code on sample datasets (`penguins`, `iris`, `mpg`, etc. ). That'll help iron out weird behavior sooner rather than later.\n",
    "![image (25).png](image%20(25).png)\n",
    "\n",
    "2021-2-21\n",
    "Daniel\n",
    "And here's the source for the function itself.\n",
    "\n",
    "\n",
    "2021-2-21\n",
    "Daniel\n",
    "Edit: The original function here depended on the factor levels of the clusters and true groups to make the color's consistent between plots (e.g. factors ordered abcdABCD not aAbBcCdD). This breaks down with some cases (e.g. if you start group names with a number (e.g. 0hours)). The below edit uses `ggnewscale`  to fix this.\n",
    "\n",
    "<https://github.com/eliocamp/ggnewscale>\n",
    "\n",
    "\n",
    "``` r\n",
    "mk_hclust_plts <- function(\n",
    "  df = unite(M_winxiqr, uid, Experiment, Cell, sep = \"-\"),\n",
    "  cluster_by = c(\"vrest\", \"r11\", \"r1\", \"Ihtk.0\", \"Ihtk.Slope\", \"Ia.0\", \"Ia.Slope\"),\n",
    "  uid_col = \"uid\",\n",
    "  n_clusters = 3,\n",
    "  true_groups = \"Condition\",\n",
    "  true_colors = RColorBrewer::brewer.pal(3, \"Set2\"),\n",
    "  cluster_colors = RColorBrewer::brewer.pal(3, \"Set1\")\n",
    "){\n",
    "  df <- as.data.frame(df) \n",
    "  \n",
    "  if (!exists(\"cluster_colors\")){\n",
    "    cluster_colors = rainbow(n_clusters)\n",
    "  }\n",
    "  ## prep\n",
    "  # move uid to rowname\n",
    "  row.names(df) <- df[[uid_col]]\n",
    "  df_groups <- select(df, all_of(true_groups))\n",
    "  df <- df[, cluster_by]\n",
    "  \n",
    "  ## Cluster\n",
    "  cluster <- pvclust(t(df),\n",
    "                     method.hclust = \"ward.D2\",\n",
    "                     method.dist = \"correlation\",\n",
    "                     use.cor = \"pairwise.complete.obs\")\n",
    "  \n",
    "  \n",
    "  ## make dendrogram  ####\n",
    "  dend <- cluster$hclust %>% \n",
    "    as.dendrogram() \n",
    "  \n",
    "  # iteratively coloring the labels is a workaround to get the \"true\" groups shown\n",
    "  dend_labs <- rownames_to_column(df_groups, var = \"rownames\")[, ]\n",
    "  dend_labs <- full_join(data.frame(rownames = labels(dend)), dend_labs)\n",
    "  for(i in seq_along(unique(df_groups[[true_groups]]))){\n",
    "    true_group <- unique(df_groups[[true_groups]])[i]\n",
    "    true_color <- true_colors[i]\n",
    "    \n",
    "    dend <- dend %>% \n",
    "      dendextend::color_labels(\n",
    "        col = true_color, \n",
    "        labels = dend_labs[dend_labs[[true_groups]] == true_group, \"rownames\"]) \n",
    "    \n",
    "    \n",
    "  }\n",
    "  \n",
    "  dend <- dend %>% \n",
    "    set(\"branches_k_color\", \n",
    "        k = n_clusters, \n",
    "        value = cluster_colors\n",
    "    ) %>% \n",
    "    set(\"branches_lwd\", 0.7) %>%\n",
    "    set(\"labels_cex\", 0.6) \n",
    "\n",
    "  dend_cluster_only <- dend %>% \n",
    "    set(\"labels_colors\",\n",
    "        k = n_clusters,\n",
    "        value = cluster_colors) %>%\n",
    "    as.ggdend()\n",
    "  \n",
    "  \n",
    "  dend <- dend %>% \n",
    "    as.ggdend()\n",
    "  \n",
    "  \n",
    "  \n",
    "  plt_dend_cluster_only <- ggplot(dend_cluster_only)+\n",
    "    theme(axis.ticks.y = element_line(),\n",
    "          axis.text.y = element_text(),\n",
    "          axis.line.y = element_line())\n",
    "  \n",
    "  \n",
    "  plt_dend <- ggplot(dend)+\n",
    "    theme(axis.ticks.y = element_line(),\n",
    "          axis.text.y = element_text(),\n",
    "          axis.line.y = element_line())  \n",
    "  \n",
    "\n",
    "  ## Add reality ribbon with or without clustering result ####\n",
    "  groups_to_plt <- full_join(\n",
    "    as.data.frame(dend$labels),\n",
    "    rownames_to_column(var = \"label\", df_groups))\n",
    "  \n",
    "  plt_grouping <- groups_to_plt %>% \n",
    "    ggplot(aes_string(x=\"x\", y=\"0\", fill = true_groups))+\n",
    "    geom_tile()+\n",
    "    scale_fill_manual(values = true_colors)+\n",
    "    theme_void()+\n",
    "    labs(x = \"\", y = \"\")+\n",
    "    theme(legend.position = \"left\")\n",
    "  \n",
    "  plt_grouping_contrast <- ggplot()+\n",
    "    geom_tile(data = groups_to_plt, aes_string(x=\"x\", y=\"0.5\", fill = true_groups))+\n",
    "    scale_fill_manual(values = true_colors)+\n",
    "    \n",
    "    ggnewscale::new_scale(\"fill\") +\n",
    "    geom_tile(data = data.frame(x = seq_along(dend_cluster_only$labels$col),\n",
    "                                cluster_groups = as.character(as.numeric(as.factor(dend_cluster_only$labels$col)))\n",
    "    ),\n",
    "    aes_string(x=\"x\", y= \"-0.5\", fill = \"cluster_groups\"),\n",
    "    )+\n",
    "    scale_fill_manual(values = cluster_colors)+\n",
    "    \n",
    "    theme_void()+\n",
    "    labs(x = \"\", y = \"\")+\n",
    "    theme(legend.position = \"left\")\n",
    "  \n",
    "  \n",
    "  ## Add heatmap  ####\n",
    "  data_to_plt <- full_join(\n",
    "    as.data.frame(dend$labels),\n",
    "    rownames_to_column(var = \"label\", df)) \n",
    "  \n",
    "  data_to_plt <- \n",
    "    data_to_plt %>% \n",
    "    gather(\"key\", \"value\", \n",
    "           names(data_to_plt)[\n",
    "             !(names(data_to_plt) %in% c(\"x\", \"y\", \n",
    "                                         \"label\", \"col\", \"cex\", \n",
    "                                         true_groups))\n",
    "           ])\n",
    "  \n",
    "  plt_heatmap_raw <- data_to_plt %>% \n",
    "    ggplot(aes(x, \n",
    "               y = key, \n",
    "               fill = value))+\n",
    "    geom_tile()+\n",
    "    scale_fill_viridis_c()+\n",
    "    labs(x = \"\", y = \"\")+\n",
    "    theme(panel.background = element_blank(),\n",
    "          axis.ticks.x = element_blank(),\n",
    "          axis.text.x = element_blank(),\n",
    "          legend.position = \"left\")\n",
    "  \n",
    "  \n",
    "  plt_heatmap_z <- data_to_plt %>% \n",
    "    group_by(key) %>% \n",
    "    mutate(mean = mean(value, na.rm = T),\n",
    "           sd = sd(value, na.rm = T)) %>% \n",
    "    mutate(value = ((value - mean)/sd)) %>% # Now Z scores\n",
    "    ggplot(aes(x, \n",
    "               y = key, \n",
    "               fill = value))+\n",
    "    geom_tile()+\n",
    "    scale_fill_viridis_c()+\n",
    "    labs(x = \"\", y = \"\")+\n",
    "    theme(panel.background = element_blank(),\n",
    "          axis.ticks.x = element_blank(),\n",
    "          axis.text.x = element_blank(),\n",
    "          legend.position = \"left\")\n",
    "  \n",
    "  \n",
    "  ## Return plots, manually tweak layout  ####\n",
    "  return(\n",
    "    list(\n",
    "      pvclust_out = cluster,\n",
    "      dendrogram_clusters = plt_dend_cluster_only,\n",
    "      dendrogram_both = plt_dend,\n",
    "      group_tile = plt_grouping,\n",
    "      group_compare_tile = plt_grouping_contrast,\n",
    "      heatmap_raw = plt_heatmap_raw,\n",
    "      heatmap_z = plt_heatmap_z\n",
    "    )\n",
    "  )\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "2021-2-21\n",
    "David Schulz\n",
    "I am going to have to find a reason to play around with this, because it looks great.  Thanks!  How can we ensure the world can benefit? Is this new and exciting to others as well?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2021-2-22\n",
    "Daniel\n",
    "It's potentially worth making available online but I don't know that it's all together too useful. The components of it make for a good starting place to write from but the function itself is fairly inflexible (e.g. in terms of clustering method and tree aesthetics). Where I think it could work nicely is in a sort of \"lab reference\" with recommended/first pass solutions to needs that come up with the sort of data we collect.\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2021-3-3\n",
    "Does anyone have an effective way to deduplicate/shave correlation data frames prior to running a KS test? An inelegant workaround seems to be to order the data frame by correlation and retain every other row. Here's some example data either with or without these duplications.\n",
    "![image (26).png](image%20(26).png)\n",
    "![image (27).png](image%20(27).png)\n",
    "\n",
    "2021-3-3\n",
    "Daniel\n",
    "I also thought about using a mutate and ifelse to paste the x/y values into an alphabetical identifier (e.g. shal, bkkca, 0.## would become bkkca-shal, 0.##) but doing that seems like a huge pain.\n",
    "\n",
    "2021-3-3\n",
    "David Schulz\n",
    "I think this is code you generated for me, no?\n",
    "\n",
    "2021-3-3\n",
    "David Schulz\n",
    "\n",
    "``` r\n",
    "temp.list <- map(unique(M$Cell), function(i){\n",
    "  M %>% \n",
    "    filter(Cell == i) %>% \n",
    "    select(-c(\"Cell\")) %>% \n",
    "    correlate(use = \"pairwise.complete.obs\", method = \"pearson\") %>% \n",
    "    shave() %>% # Prevent double counting of correlations\n",
    "    mutate(Cell = i)\n",
    "})\n",
    "```\n",
    "\n",
    "\n",
    "2021-3-3\n",
    "David Schulz\n",
    "I'll put the whole thing in here, just to make sure.  Either you generated this for me (which it has your fingerprints on it), or I pilfered this from somewhere.\n",
    "\n",
    "2021-3-3\n",
    "David Schulz\n",
    "\n",
    "``` r\n",
    "\n",
    "{r}\n",
    "library(corrr)\n",
    "M <- STGGOI\n",
    "\n",
    "temp.list <- map(unique(M$Cell), function(i){\n",
    "  M %>% \n",
    "    filter(Cell == i) %>% \n",
    "    select(-c(\"Cell\")) %>% \n",
    "    correlate(use = \"pairwise.complete.obs\", method = \"pearson\") %>% \n",
    "    shave() %>% # Prevent double counting of correlations\n",
    "    mutate(Cell = i)\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "M <- do.call(rbind, temp.list)\n",
    "M <- M %>% \n",
    "  gather(colname, cor, names(select(M, -c(\"rowname\", \"Cell\")))) \n",
    "\n",
    "#M <- subset(M, cor >= 0.5)\n",
    "plot_ecdf_ks <- function(\n",
    "  df = temp.df,\n",
    "  data.col = \"cor\",\n",
    "  group.col = \"data\",\n",
    "  group1 = \"0\",\n",
    "  group2 = \"24\",\n",
    "  colors = c(\"#4d4d4d\", \n",
    "             #\"#67a9cf\", \n",
    "             \"#1c9099\")) {\n",
    "  \n",
    "  # Adapted from:\n",
    "  # <https://rpubs.com/mharris/KSplot>\n",
    "  df <- filter(df, df[[group.col]] %in% c(group1, group2))\n",
    "  \n",
    "  df[df[[group.col]] == group1, data.col]\n",
    "  \n",
    "  \n",
    "  data1 <- unlist(df[df[[group.col]] == group1, data.col])\n",
    "  data2 <- unlist(df[df[[group.col]] == group2, data.col])\n",
    "  \n",
    "  ecdf1 <- ecdf(data1)\n",
    "  ecdf2 <- ecdf(data2)\n",
    "  \n",
    "  # used to get the most extreme difference between the two samples\n",
    "  MostExtremeDiff <- seq(min(data1, data2, na.rm = T), max(data1, data2, na.rm = T), length.out = length(data1))\n",
    "  x0 <- MostExtremeDiff[which(abs(ecdf1(MostExtremeDiff) - ecdf2(MostExtremeDiff)) == \n",
    "                                max(abs(ecdf1(MostExtremeDiff) - ecdf2(MostExtremeDiff))))]\n",
    "  y0 <- ecdf1(x0)\n",
    "  y1 <- ecdf2(x0)\n",
    "  \n",
    "  graph.df <- data.frame(data1, data2) %>% gather(Condition, Value, 1:2)\n",
    "  graph.df[graph.df$Condition == \"data1\", \"Condition\"] <- group1\n",
    "  graph.df[graph.df$Condition == \"data2\", \"Condition\"] <- group2\n",
    "  \n",
    "  # Run two sided KS test on data\n",
    "  test.res <- ks.test(data1, data2)\n",
    "  \n",
    "  plt <- \n",
    "    ggplot(graph.df)+\n",
    "    geom_segment(aes(x = x0[1], y = y0[1], xend = x0[1], yend = y1[1]),\n",
    "                 linetype = \"dashed\", color = \"black\", size = 1)+\n",
    "    geom_point(aes(x = x0[1] , y= y0[1]), color=\"black\", size=2) +\n",
    "    geom_point(aes(x = x0[1] , y= y1[1]), color=\"black\", size=2) +\n",
    "    stat_ecdf(aes(x = Value, group = Condition, color = Condition))+\n",
    "    labs(x = \"Sample\", \n",
    "         y = \"ECDF\", \n",
    "         title = paste(\"K-S Test\", as.character(group1), \"vs\", as.character(group2), \n",
    "                       \"\\np-value:\", as.character(test.res$p.value, digits = 4)))+\n",
    "    theme_minimal()+\n",
    "    theme(legend.position = \"bottom\")+\n",
    "    scale_color_manual(values = colors)#+\n",
    "    # theme(text=element_text(family=\"Calibri Light\", size=14)) \n",
    "  \n",
    "  return(plt)\n",
    "  \n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "``` r\n",
    "\n",
    "\n",
    "2021-3-3\n",
    "Daniel\n",
    "Yeah I think this is from me. `shave`  is from `library(corrr)`  and achieves this nicely. I was thinking after the data's in long format, but the solution may just be to do it on the front end instead of after it's long.\n",
    "\n",
    "2021-3-3\n",
    "David Schulz\n",
    "So in other words I answered your question by facilitating a conversation between you and yourself. You're welcome.  :slightly_smiling_face:\n",
    "\n",
    "2021-3-3\n",
    "Daniel\n",
    "I appreciate it.\n",
    "\n",
    "For anyone using this in the future, `shave`  doesn't work with dataframes or the output of `cor`  so you'll need to run `as.data.frame` after shaving it.\n",
    "\n",
    "2021-3-3\n",
    "Daniel\n",
    "Found some code I wrote to do this following `cor`.\n",
    "This is probably only worth doing this way if you're calculating p values (for corplot) since the same strategy can be applied to a `p.mat`.\n",
    "\n",
    "\n",
    "```\n",
    "  cor_df <- cor(cor_df, use = \"pairwise.complete.obs\")\n",
    "  \n",
    "  # Shave to diagonal\n",
    "  for (j in seq(1, nrow(cor_df))){\n",
    "    cor_df[j, 1:j] <- NA\n",
    "  }\n",
    "``` r\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2021-3-5\n",
    "Two tricks today:\n",
    "1. Scale fill functions can accept breaks and limit arguments so you don't have to use hacky workarounds like binning the data before plotting (which is what I usually do).\n",
    "2. `library(ggtext)` lets you render markdown within plots (e.g. for those pesky mRNAs)\n",
    "\n",
    "```\n",
    "> df\n",
    "# A tibble: 540 x 4\n",
    "   term   Condition term2    Cor\n",
    "   <chr>  <chr>     <chr>  <dbl>\n",
    " 1 bkkca  0h        vrest -0.420\n",
    " 2 cav1   0h        vrest -0.252\n",
    " 3 cav2   0h        vrest -0.276\n",
    " 4 inx1   0h        vrest -0.313\n",
    " 5 inx2   0h        vrest -0.327\n",
    "``` r\n",
    "\n",
    "Before:\n",
    "\n",
    "```\n",
    "df %>% \n",
    "  ggplot(aes(term, term2, fill = Cor))+\n",
    "  geom_tile()+\n",
    "  labs(x= \"mRNA\", y = \"\")+\n",
    "  scale_fill_distiller(palette = \"PuOr\")+\n",
    "  coord_fixed()\n",
    "``` r\n",
    "\n",
    "After:\n",
    "\n",
    "```\n",
    "library(ggtext)\n",
    "library(glue)\n",
    "\n",
    "df %>% \n",
    "  mutate(term = glue((\"<i>{term}</i>\"))) %>%  \n",
    "  ggplot(aes(term, term2, fill = Cor))+\n",
    "  geom_tile()+\n",
    "  labs(x= \"mRNA\", y = \"\")+\n",
    "  \n",
    "  theme(axis.text.x = element_markdown(angle = 45))+ # <-- Note that we have element_markdown not element_text\n",
    "  \n",
    "  scale_fill_stepsn(\n",
    "    colors=RColorBrewer::brewer.pal(n = 8, name = \"PuOr\"),\n",
    "    na.value = \"transparent\",\n",
    "    breaks=round(seq(-1, 1, length.out = 8), digits = 2),\n",
    "    limits=c(-1,1)\n",
    "  )+\n",
    "  coord_fixed()\n",
    "``` r\n",
    "\n",
    "![image (28).png](image%20(28).png)\n",
    "![image (29).png](image%20(29).png)\n",
    "\n",
    "2021-3-5\n",
    "Daniel\n",
    "<https://github.com/wilkelab/ggtext>\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2021-3-9\n",
    "Another useful trick is to pass expressions into ggplot. Here I've used the following as arguments in `labs()`.\n",
    "\n",
    "\n",
    "```\n",
    "c(\"r11\", \"r1\", \"Ihtk.0\", \"Ihtk.Slope\", \"Ia.0\", \"Ia.Slope\", \"vrest\")\n",
    "c(expression(M~Omega), expression(M~Omega), \"nA\", expression(frac(nA, mV)), \"nA\", expression(frac(nA, mV)), \"mV\" )\n",
    "``` r\n",
    "\n",
    "\n",
    "![image (30).png](image%20(30).png)\n",
    "\n",
    "2021-3-9\n",
    "Daniel\n",
    "You can also do something like this `theme(plot.title = element_text(face=\"italic\"))`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "2021-3-11\n",
    "Reordering a discrete axis in ggplot after generation a lot simpler than one might expect.  Rather than converting a character column to a factor (what if the data gets pivoted?), or using one column for the position and one for the labels, you can use `xlim` or `ylim`.\n",
    "\n",
    "```\n",
    "> mrna_cols # desired order\n",
    "# [1] \"nav\"    \"cav1\"   \"cav2\"   \"bkkca\"  \"shaker\" \"shal\"   \"shab\"   \"shaw1\" \n",
    "# [9] \"shaw2\"  \"inx1\"   \"inx2\"   \"inx3\"  \n",
    "\n",
    "o_mrna$heatmap_z / # ggplot object within a list\n",
    "o_mrna$heatmap_z+ylim(mrna_cols)\n",
    "``` r\n",
    "\n",
    "\n",
    "![image (31).png](image%20(31).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2021-3-23\n",
    "R's distribution simulation functions (e.g. `dbinom`, `runif`) make it quick and easy to double check one's intuitions. For example, I'd been thinking that under H0 the distribution of correlations from normal samples should drop off sharply as you go away from 0 such that a shift in correlation from 0 -> 0.1 is much more likely than 0.8 -> 0.9.\n",
    "\n",
    "\n",
    "So I used `purrr::map()` to run a quick simulation. Here we simulate the null distribution based on 100,000 observations and compute the chance of a value being above 0.7. If it was uniform we would expect ~15% (.03/2) of the distribution to be here but end up with ~1.2% with the drop off.\n",
    "\n",
    "```\n",
    "set.seed(89745)\n",
    "cor_check <- map(1:100000, function(i){ \n",
    "  cor(rnorm(10), rnorm(10), method = \"pearson\")\n",
    "})\n",
    "cor_check <- data.frame(cor = do.call(rbind,  cor_check))\n",
    "ggplot(cor_check, aes(x = cor))+  geom_histogram(binwidth = 0.05)\n",
    "mean(cor_check$cor >= 0.7)*100\n",
    "# 1.227 Percent\n",
    "``` r\n",
    "\n",
    "\n",
    "![image (32).png](image%20(32).png)\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2021-9-7\n",
    "Daniel\n",
    "<https://github.com/seatgeek/fuzzywuzzy|https://github.com/seatgeek/fuzzywuzzy> this is a tool that isn’t necessary most of the time but when it is it can save a ton of time. It lets you do approximate string matching. I’ve used it for handling typos and differences in white space/ punctuation/ naming conventions in entry labels and it’s worked nicely. There’s a port for R and a few other languages too. \n",
    "\n",
    "2021-9-7\n",
    "Joe\n",
    "Thanks zombie Daniel \n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2022-5-31\n",
    "Daniel\n",
    "ggplot tip: if you use an eight digit hex code for specifying a color value, the first two control transparency. Thus, you can set `fill` `=` `“#00000000”` in ggplot to get a boxplot with no fill.\n",
    "\n",
    "2022-5-31\n",
    "Here's the use case: points on top occlude the cross bar but box on top hides the observations. You could also do this by changing alpha but I think that will alter the lines as well.\n",
    "![Image from iOS](Image from iOS.jpg)\n",
    "\n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2023-5-23\n",
    "Daniel\n",
    "R treats # as a comment in text files. \n",
    "\n",
    "A file I have (hapmap of snps) included one in a field of the header. If your look at the words on the first to lines with wc they will agree but R will fail to load the file. The solution is to pass in an explicit comment character like so `read.table(“snps.txt”, comment.char=‘’)`. \n",
    "\n",
    "\n",
    "-xcutx-\n",
    "\n",
    "\n",
    "2024-3-21\n",
    "Daniel\n",
    "<https://blog.moertel.com/posts/2006-01-20-wondrous-oddities-rs-function-call-semantics.html|https://blog.moertel.com/posts/2006-01-20-wondrous-oddities-rs-function-call-semantics.html>\n",
    "\n",
    "This is the sort of thing you don’t realize until it would be _really_ useful to access the name of a variable or run text as if it were code. I think the most accessible example of R’s wizardry is in plotting- you pass variables (time, mv) to plot or ggplot instead of strings (“time”, “mv”) and magically you get axis labels. R gets access to the _value_ of a variable _*and*_ its name and no one notices because it just works. :exploding_head:  ```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5efbb912",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [e.strip('\\n') for e in all_text.split('-xcutx-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d88a4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-4-1\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  You can keep your working `Rmd` easier to navigate and less buggy by 1) packaging code into functions and 2) adding them to a companion `R` file. Load your functions with `source()` in the same block you load your libraries with a relative path, full path, or ideally with `here()`.\n",
      "\n",
      "``` r\n",
      "library(here)\n",
      "source(here(\"R\", \"02MoniterGapJunction.R\")) #here's output is effectively ../R/02MoniterGapJunction.R\n",
      "```\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-4-10\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you're iteratively making plots, resampling, or doing another task that would have your reach for a for loop or `lapply()` use `furrr::future_map()` instead. `furrr` gives parallel processing ready versions of tidyverse's `purrr` functions (e.g. `map()`,  `walk()`). It's easy to install the dependencies and takes a lot of the headache out of parallel processing.\n",
      "![cpu_use_1.PNG](cpu_use_1.PNG)\n",
      "![cpu_use_0.PNG](cpu_use_0.PNG)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-4-20\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you're running low on memory, you can retain specific objects by running this:\n",
      "\n",
      "``` r\n",
      " \n",
      "# get rid of everything\n",
      "rm(list=ls())\n",
      "\n",
      "# get rid of everything except specific objects and all loaded functions\n",
      "rm(list = \n",
      "   ls()[!(ls() %in% c(\n",
      "   # objects\n",
      "   c(\"data1\", \"data2\", \"bool1\", \"list1\"), \n",
      "   # functions\n",
      "   lsf.str())\n",
      "   ) ])\n",
      "```\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-4-20\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  `lsf.str()` returns a character string of the functions you've written. This doesnt' include functions from libraries so it may not be needed if you have used `source()` to pull your custom functions from `/R/`.\n",
      "\n",
      "2020-4-20\n",
      "If you're tempted to use `rm(list = ls())` consider restarting your r session (`ctrl+shift+F10` on windows). Overreliance on `rm(list = ls())` is poor form and the Rstudio devs will know and find you.\n",
      "![image.png](image.png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-4-21\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you're applying the same theme to all your graphs, set it globally instead e.g. `theme_set(ggplot2::theme_minimal())`.  If you have a lot of custom changes to your theme, throw those into a function and set that to the global theme.\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-5-4\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you're on windows, `installr` should allow you to copy over the libraries from previous versions.\n",
      "![image (1).png](image%20(1).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-5-6\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Don't get suckered when converting factors! Numeric data can be assigned to a factor type which will throw a wrench in a plot or analysis (1/3)\n",
      "![image (2).png](image%20(2).png)\n",
      "\n",
      "2020-5-6\n",
      "A knee jerk reaction would be to convert it to a numeric with `as.numeric()`. That doesn't work either.  (2/3)\n",
      "![image (3).png](image%20(3).png)\n",
      "\n",
      "2020-5-6\n",
      "However if you use `as.numeric(as.character())` then it works. That's because factors are ordinal and named so if you convert the type to character first to ensure R is working with the factor names instead of the ranks. (3/3)\n",
      "![image (4).png](image%20(4).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-5-11\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Need a quick base `R` syntax lookup? Check out <https://learnxinyminutes.com/docs/r/> .  There are even examples with `lm()` and `glm()`.\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-5-11\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  tldr: `tidyverse` function variants take slightly different input. Testing out a variant or two can save you a lot of debugging time.\n",
      "\n",
      "In `tidyverse` watch out for inconsistencies in function versions. There are variants of common functions (e.g. `mutate()` `mutate_all()` `mutate_at()`) don't necessarily behave the same way (or how you would expect).\n",
      "\n",
      "Here, I was applying an operation to a grouped df where each `Experiment` contains several `FileName`s with multiple observations in each.  To keep everything reusable I'm using `exp` instead of `Experiment` to select the right col.\n",
      "\n",
      "``` r\n",
      "> exp = \"Experiment\"\n",
      "> rec = \"FileName\"\n",
      "\n",
      "> df %>%\n",
      "+     dplyr::select(\n",
      "+       exp, rec, r11, r12\n",
      "+     )\n",
      "# A tibble: 564 x 4\n",
      "   Experiment FileName           r11   r12\n",
      "   <chr>      <chr>            <dbl> <dbl>\n",
      " 1 190808a    190808a_0020.abf  5.06 0.150\n",
      " 2 190808a    190808a_0020.abf  5.13 0.160\n",
      " 3 190808a    190808a_0020.abf  5.11 0.122\n",
      " 4 190808a    190808a_0020.abf  2.49 0.152\n",
      " 5 190808a    190808a_0020.abf  2.49 0.195\n",
      "# ... with 559 more rows\n",
      "```\n",
      "\n",
      "As soon as we do the same thing with `group_by()` we don't get the right column even though `select()` didn't have an issue with `exp`.\n",
      "\n",
      "``` r\n",
      "> df %>%\n",
      "+     dplyr::select(\n",
      "+       exp, rec, r11, r12\n",
      "+     ) %>%\n",
      "+     group_by(exp, rec)\n",
      "Error: Column `exp` is unknown\n",
      "```\n",
      "\n",
      "So we can try explicitly selecting the columns we want as groupings.\n",
      "\n",
      "``` r\n",
      ">     df %>%\n",
      "+     dplyr::select(\n",
      "+       exp, rec, r11, r12\n",
      "+     ) %>%\n",
      "+     group_by(vars(exp, rec))\n",
      "Error: Column `vars(exp, rec)` must be length 564 (the number of rows) or one, not 2\n",
      "```\n",
      "\n",
      "No dice there. `vars()` is designed to work with the `_at` variants so we can try that.  _et voilà!_\n",
      "\n",
      "``` r\n",
      "> df %>%\n",
      "+     dplyr::select(\n",
      "+       exp, rec, r11, r12\n",
      "+     ) %>%\n",
      "+     group_by_at(vars(exp, rec))\n",
      "\n",
      "# A tibble: 564 x 4\n",
      "# Groups:   Experiment, FileName [69]\n",
      "   Experiment FileName           r11   r12\n",
      "   <chr>      <chr>            <dbl> <dbl>\n",
      " 1 190808a    190808a_0020.abf  5.06 0.150\n",
      " 2 190808a    190808a_0020.abf  5.13 0.160\n",
      " 3 190808a    190808a_0020.abf  5.11 0.122\n",
      " 4 190808a    190808a_0020.abf  2.49 0.152\n",
      " 5 190808a    190808a_0020.abf  2.49 0.195\n",
      "# ... with 559 more rows\n",
      "```\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-5-12\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Save `R` objects as rds. These could be works in progress or items that take a while to generate (e.g. re-sampled results). This gives the utility of saving a work space without the dangers.\n",
      "\n",
      "``` r\n",
      "library(here)\n",
      "save(df, file = here(\"data\", \"df.rds\"))\n",
      "# df is now saved at ./data/df.rds\n",
      "\n",
      "load(here(\"data\", \"df.rds\"))\n",
      "# df is now loaded from ./data/df.rds as df\n",
      "```\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-5-15\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you're using git for version control, don't forget about the `.gitignore` file. Anything large and static (like .abfs) or procedurally generated (e.g. plots) you can toss in the `.gitignore` and you'll not see it when you commit.\n",
      "\n",
      "I have tabular data that lives in `./inst/extdata/` is processed by a script and then saved as a .rds in `./data/`.  Here's my `.gitignore`.\n",
      "\n",
      "\n",
      "``` r\n",
      ".Rproj.user\n",
      ".Rhistory\n",
      ".RData\n",
      ".Ruserdata\n",
      "# Don't track ABFs -- large and static\n",
      "*.abf\n",
      "# Don't track files that are generated from the scripts\n",
      "/data/*\n",
      "```\n",
      "\n",
      "For more check out <https://git-scm.com/docs/gitignore>\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-5-19\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you need to include greek letters or special characters in a plot use `annotate()` instead of `geom_text()`. On my machine it preforms a *lot* faster.\n",
      "\n",
      "\n",
      "``` r\n",
      "# 57.62977 secs\n",
      "geom_text(aes(x = 15, y = 25, label = \"phi~22.5\"), parse=TRUE)\n",
      "# 1.988642 secs\n",
      "annotate(\"text\", x = 15, y = 25, parse = TRUE, label = as.character(expression(paste(phi, \" 22.5\"))))\n",
      "```\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-5-19\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Use `geom_rect()` with the min/max set to `-Inf` and `Inf` to add a pleasant shading to your facets.\n",
      "\n",
      "For example by passing it a data frame with the faceting variables and a column to use for the color (green if positive, red if negative) we can make facets behave like cells in  a heatmap!\n",
      "\n",
      "``` r\n",
      "# > tp2\n",
      "# # A tibble: 23 x 5\n",
      "#    Condition   Trace             Time  Change StimId\n",
      "#    <fct>       <chr>             <chr>  <dbl> <chr> \n",
      "#  1 PS.0.orig   170623b_0007.abf  60         1 a     \n",
      "#  2 PS.45.orig  170825a_0008.abf  60        -1 c     \n",
      "\n",
      "ggplot(df)+\n",
      "  geom_rect(data = tp2, aes(fill = Change),xmin = -Inf,xmax = Inf, ymin = -Inf,ymax = Inf,alpha = 0.3) +\n",
      "  geom_hline(yintercept = 0, color = \"cornflowerblue\")+\n",
      "  geom_pointline(aes(x = Time, y = rc, group = Experiment), shape = 1, color = \"black\")+\n",
      "  ylim(-2, 3.5)+\n",
      "  scale_fill_gradientn(colors = c(\"Red\", \"Grey\", \"Green\"))+\n",
      "  theme_base()+\n",
      "  theme(legend.position = \"\")\n",
      "```\n",
      "\n",
      "![image (5).png](image%20(5).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-5-26\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Handy trick:\n",
      "Write your test results into a summary csv. Then while writing you can insert a link to the cell value for a result into your .doc. After that, changing post hoc corrections, re-sampling iterations, or data QC just requires you to re-run your code and let word refresh all the links.\n",
      "\n",
      "You can also do this from excel, but you'll have to update the formula for the cell used instead.\n",
      "\n",
      "<#C010AS4PSUX|data_analysis>\n",
      "![AutoUpdateStats.gif](AutoUpdateStats.gif)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-6-4\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you're looking at linear relationships, give this code a spin. It'll automatically flag outliers based on 1.5*IQR and show you the fit with and without the outliers.  Since the output is a ggplot, you and add to it or tweak the aesthetics of the output (see example below). If anyone has a favorite outlier detection method and ends up modifying this, please post it here so we can see it! <@U0103JSQYLB> <@U010CH4JLKE> <@U010M1M3N9E>\n",
      "\n",
      "Here's the function.\n",
      "\n",
      "``` r\n",
      "scatter_w_wo_outliers <- function(temp = filter(M, Time == \"Baseline\"),\n",
      "                                  X = \"bkkca\", \n",
      "                                  Y = \"Ihtk.0\"){\n",
      "  \n",
      "  # flag outliers based on 1.5xIQR from median\n",
      "  X_low  <- median(temp[[X]], na.rm = T) - (1.5 * IQR(temp[[X]], na.rm = T))\n",
      "  X_high <- median(temp[[X]], na.rm = T) + (1.5 * IQR(temp[[X]], na.rm = T))\n",
      "  Y_low  <- median(temp[[Y]], na.rm = T) - (1.5 * IQR(temp[[Y]], na.rm = T))\n",
      "  Y_high <- median(temp[[Y]], na.rm = T) + (1.5 * IQR(temp[[Y]], na.rm = T))\n",
      "  \n",
      "  X_pass <- (temp[[X]] > X_low) * (temp[[X]] < X_high)\n",
      "  Y_pass <- (temp[[Y]] > Y_low) * (temp[[Y]] < Y_high)\n",
      "\n",
      "  temp$flag <- ifelse((X_pass * Y_pass) == 1, T, F)\n",
      "  \n",
      "  \n",
      "  # Duplicate so we have dataset 1, 2 (introduces duplicates)\n",
      "  temp <- rbind(temp[temp$flag == T, ], mutate(temp, flag = F))\n",
      "  \n",
      "  formula1 <- y ~ x\n",
      "  \n",
      "  plt <- ggplot(temp, aes_string(X, Y, color = \"flag\"))+\n",
      "    geom_smooth(data = temp, method = lm, se = F, fullrange = T)+\n",
      "    geom_point(data = temp)+\n",
      "    geom_point(data = temp, color = \"black\", shape = 1)+\n",
      "    geom_point(data = temp[temp$flag, ])+\n",
      "    ggpmisc::stat_poly_eq(aes(label =  paste(stat(eq.label), \"*\" with \"*\", \n",
      "                                             stat(rr.label), \"*\", \"*\", \n",
      "                                             stat(f.value.label), \"*\", and \"*\",\n",
      "                                             stat(p.value.label), \"*\".\"\",\n",
      "                                             sep = \"\")),\n",
      "                          formula = formula1, parse = TRUE, size = 4)+\n",
      "    \n",
      "    scale_color_manual(values = c(\"darkgray\", \"black\"))+\n",
      "    theme_bw()+\n",
      "    theme(legend.position = \"\")\n",
      "  \n",
      "  return(plt)\n",
      "}\n",
      "```\n",
      "\n",
      "Here's a reproducible example. We're creating a Simpson's paradox by giving the \"outliers\" a negative slope and the real data a positive slope. I've added a red line showing the true relationship.\n",
      "\n",
      "``` r\n",
      "set.seed(45645684)\n",
      "df <- data.frame(x = rnorm(30, mean = 10, sd = 4),\n",
      "                 noise = runif(30, min = -2, max = 2),\n",
      "                 y = NA,\n",
      "                 is_outlier = rbinom(30, 1, prob = 0.2))\n",
      "\n",
      "\n",
      "df$y <- ifelse(df$is_outlier, \n",
      "               -5*df$x+df$noise,\n",
      "               2*df$x+df$noise)\n",
      "\n",
      "scatter_w_wo_outliers(temp = df,\n",
      "                      X = \"x\",\n",
      "                      Y = \"y\")+\n",
      "  geom_abline(slope = 2, intercept = 0, color = \"firebrick\")\n",
      "```\n",
      "\n",
      "![image (7).png](image%20(7).png)\n",
      "\n",
      "\n",
      "2020-6-4\n",
      "Daniel\n",
      "Here's a related utility function. For a given column it'll return a logical vector where outliers are `FALSE`.\n",
      "\n",
      "``` r\n",
      "w_in_x_iqr <- function(col_in, multiplier = 1.5){\n",
      "  col_in <- as.vector(col_in)\n",
      "  \n",
      "  X_low  <- median(col_in, na.rm = T) - (multiplier * IQR(col_in, na.rm = T))\n",
      "  X_high <- median(col_in, na.rm = T) + (multiplier * IQR(col_in, na.rm = T))\n",
      "  X_pass <- (col_in > X_low) * (col_in < X_high)\n",
      "  \n",
      "  return(as.logical(X_pass))\n",
      "}\n",
      "```\n",
      "\n",
      "e.g.\n",
      "\n",
      "``` r\n",
      "> mutate(M, ex = w_in_x_iqr(bkkca)) %>% select(bkkca, ex) %>% arrange(bkkca) %>% tail()\n",
      "\n",
      "#  A tibble: 6 x 2\n",
      "#   bkkca ex   \n",
      "#   <dbl> <lgl>\n",
      "# 1 3056. TRUE \n",
      "# 2 3222. TRUE \n",
      "# 3 3255. TRUE   # Within bounds\n",
      "# 4 3552. FALSE  # Outside bounds \n",
      "# 5 3817. FALSE\n",
      "# 6 6740. FALSE\n",
      "```\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-6-5\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  ggplot's, `element_text()` comes with a color argument. Why does that matter? It doesn't just accept atomics, you can hand it a _vector_! This effectively gives one access to conditional formatting. This works on `ggplot2_3.3.0` but \"vectorized input to `element_text()` is not officially supported\" so YMMV with newer versions.\n",
      "\n",
      "Here's an example I think it makes an otherwise unbearable figure a little more so without requiring duplicated labels.\n",
      "\n",
      "One thing to be aware of is the ordering of a character/ factor may differ between a data.frame and the plot. In the visualized example, I had `mRNA` as type character instead of factor so it got alphabetized when it was plotted rather than by the order appearing in the data.frame.\n",
      "![image (8).png](image%20(8).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-6-12\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Trying something new here-- \"Function Friday\". If you've written a function you're rather pleased with, used one in a creative way, or know one that you think deserves it's time in the sun please share it here.\n",
      "\n",
      "I'll start. Y'all should be using `unlist()`. `unlist` is a crazy handy function when you pair it with the `purrr` library. It'll take a list and try to give you a vector. Strictly speaking it's probably best to be using `map_dbl()` or `map_chr()` instead but let's not worry about that at the moment.\n",
      "\n",
      "Why do I love `unlist` so much? Because `unlist(map( ))` gives you a flexible, effective way to iterate (that is parallel friendly with minor changes).\n",
      "\n",
      "Here's an example: I have a bunch of traces in a folder and I need to know if there are any experiments that didn't copy. Additionally, I'd like to know what kind of data is in the file. I _could_ look through them one by one, but that's no fun. Thankfully, R has functions that perform similarly to shell functions. (More on these some other time.)\n",
      "\n",
      "So we start by defining a data.frame with all file names and their sizes. Note that calling `unlist(map())` _inside_ `data.frame()` lets us do a lot work very quickly. We find all the files, get information about each one, and then selectively return the size.\n",
      "\n",
      "``` r\n",
      "traces_dir <- \"C:/Users/Daniel/Documents/Trace_Holding\"\n",
      "\n",
      "files_df <- data.frame(files = list.files(traces_dir),\n",
      "                       bytes = unlist(map(list.files(traces_dir), \n",
      "                                          function(abf){ <http://file.info|file.info>(paste0(traces_dir, \"/\",abf))$size })))\n",
      "\n",
      "#              files    bytes\n",
      "# 1 190808a_0000.abf 15006208 <- long gap free recording\n",
      "# 2 190808a_0001.abf 15006208\n",
      "# 3 190808a_0002.abf 15006208\n",
      "```\n",
      "\n",
      "The experiment is embedded in the file name for each. Once again , with a little help from `unlist` we can split the file names into a list of list (i.e. `\"190808a_0000.abf\"` becomes `[[1]] [[1]] \"190808a\" [[2]] \"0000.abf\"` select only the first part and populate a new column.\n",
      "\n",
      "``` r\n",
      "files_df$Experiment <- unlist(transpose(str_split(files_df$files, pattern = \"_\"))[[1]])\n",
      "```\n",
      "\n",
      "\n",
      "Okay, now we can make use of this. I've defined a data.frame for metadata about the experiments.\n",
      "\n",
      "``` r\n",
      "file_groups\n",
      "#    Experiment       Group\n",
      "# 1      190924    Baseline\n",
      "# ... \n",
      "# 19     190918     Delayed\n",
      "```\n",
      "\n",
      "We can join these data frames and apply a little `tidyverse` magic to see what experiments are missing (we could also compare the sets of experiments directly).\n",
      "\n",
      "``` r\n",
      "full_join(file_groups, files_df) %>% \n",
      "  filter(<http://is.na|is.na>(files)) %>% \n",
      "  group_by(Group, Experiment) %>% \n",
      "  tally()\n",
      "\n",
      "#  Experiments that didn't transfer:\n",
      "\n",
      "#   Group       Experiment     n\n",
      "# 1 Baseline    190924         1\n",
      "# 2 Baseline    190924a        1\n",
      "# ...\n",
      "```\n",
      "\n",
      "We can repeat the same strategy to programattically look at the protocol types (e.g. based on file size or channel number via `<http://file.info|file.info>` | `readABF()`). Moral of the story, you should so stop `apply`ing yourself and give `unlist` and `purrr` functions a try.\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-6-15\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you run into a situation where you're using a ton of memory (e.g. manipulating transcriptomic data, resampling, or working with electrophysiology traces)  use `rm()` to selectively get rid off objects in the environment. A useful pattern is to write out large objects you'll need in the future, remove them, and then read them back in when you need them. This is usually not important, but when it is, it is.\n",
      "\n",
      "A side note -- unlike listing items where the function matching the unix command acts on the environment and a new command acts on the files system (`ls()` and `list.files()`) the functions for removing items don't follow this logic. `rm()` acts on objects in your environment whereas `unlink()` acts on system files.\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-6-25\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  The `tictoc` library has convenience functions for timing code.  Here’s the basic usage relative to timing with base R.\n",
      "\n",
      "``` r\n",
      "library(tictoc)\n",
      "tic()\n",
      "# code here\n",
      "toc()\n",
      "\n",
      "tic <- Sys.time()\n",
      "# code here\n",
      "toc <- Sys.time()\n",
      "print(toc - tic)\n",
      "```\n",
      "\n",
      "Where this library excels is when you want to time multiple parts of your code. Each `tic` pushes the time onto a stack and each `toc` pops the most recent time from said stack. That means you don’t have to worry about assigning several timing variables even if you want to time nested code.\n",
      "\n",
      "``` r\n",
      "tic()\n",
      "# stack is 1 deep\n",
      "for (i in 1:10) {\n",
      "     tic()\n",
      "     # stack is now 2 deep\n",
      "     for (j in 1:10){\n",
      "          tic()\n",
      "          # stack is now 3 deep\n",
      "          toc()\n",
      "     }\n",
      "     toc()\n",
      "}\n",
      "toc()\n",
      "```\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-7-28\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  In tidyverse you can use `.` to reference the current dataframe. This is really useful for plotting. For example, I'd like to plot channels In7 and In12 in that order but by default In12 will come first. We could save an intermediate dataframe and re-level the factors, but by referencing the dataframe piped into mutate we can skip this step.\n",
      "\n",
      "\n",
      "``` r\n",
      "temp %>% # temp is a down-sampled ephys recording\n",
      "  ungroup() %>% \n",
      "  gather(key, value, c(\"In7\", \"In12\")) %>% \n",
      "  mutate(key = factor(.$key, levels = c(\"In7\", \"In12\"))) %>%      # Note that if you have groupings, you'll need to get rid of them or supply a column of the same length as the group. \n",
      "  ggplot(aes(Time, value, color = key, group = interaction(key, Sweep)))+\n",
      "  geom_path()\n",
      "```\n",
      "\n",
      "\n",
      "![image (11).png](image%20(11).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-7-30\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you want to make future you more positively disposed to present you, then organize your work with `R` packages, save your custom functions in the `/R/` directory. The function `roxygen2::roxygenise()` will documentation comments for your functions into help pages. For example running `roxygenise()` with the below function saved produces the attached help page accessible via `?shrug`.\n",
      "\n",
      "\n",
      "``` r\n",
      "#' @title Print Shrug\n",
      "#' @description This function prints a shrug emoji a specified number of times, provided the input value is a numeric greater than zero.\n",
      "#' @param n how many shrugs should be printed\n",
      "#' @author Daniel Kick (\\email{daniel.r.kick@@gmail.com})\n",
      "#' @export\n",
      "#' @examples\n",
      "#' shrug(5)\n",
      "\n",
      "shrug <- function(n = 1, ...){\n",
      "  if (is.numeric(n) & n>0){\n",
      "    for (i in seq(1, n)){\n",
      "        cat(\"¯\\_(ツ)_/¯\n",
      "\")\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "![image (12).png](image%20(12).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-8-22\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Be mindful of your data types. Sometimes `T == 1 == 1.0` (logical, int, double) but assuming these are equivalent can get you into trouble. For example, in these animations, the only difference is the data is coerced to logicals or integers.\n",
      "![conway_bool.gif](conway_bool.gif)\n",
      "![conway_int.gif](conway_int.gif)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-9-19\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  If you're working on data that takes a long time to process, consider adding a the following to your analysis.\n",
      "\n",
      "``` r\n",
      "save.image(file='myEnvironment.RData')\n",
      "load('myEnvironment.RData')\n",
      "```\n",
      "\n",
      "This will let you reload your environment. One can also by default save your environment when closing Rstudio but that may make it easy to reference objects that no longer are generated in the document itself thereby speeding software rot.\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-11-4\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  <@U010CH4JLKE> As an example to show how accessible this is, here's bit of code that resamples an anova and computes an empirical p value.\n",
      "\n",
      "`temp` is a dataframe containing the data\n",
      "`Condition` is a column with exactly that\n",
      "`temp_col` is the name of a dependent variable. It's a string to make this easy to reuse.\n",
      "if you haven't used `map` before it's basically a for loop that returns a list. When the output get's passed into `unlist` it becomes an array.\n",
      "\n",
      "\n",
      "``` r\n",
      "temp_shuffle <- temp\n",
      "resample_array <- map(1:1000, function(i){\n",
      "     temp_shuffle$Condition <- sample(temp_shuffle$Condition, replace = F)\n",
      "     fm <- lm(as.formula(paste0(temp_col, \" ~ Condition\")), data = temp_shuffle)      \n",
      "     return(car::Anova(fm)[1,3])\n",
      "}) %>% unlist()\n",
      "ep <- mean(resample_array >= car::Anova(fm)[1,3])\n",
      "```\n",
      "\n",
      "The down side is that it takes orders of magnitude more time to run because you're running the same code hundreds or thousands of times. This is only a problem if you need crazy high precision or have a really complex/hard to fit model. For reference using the code above took about ~2 seconds/dv for 1000 iterations on my machine.\n",
      "\n",
      "2020-11-4\n",
      "Daniel\n",
      "<@U0103JSQYLB>  A handy pattern is to use map to summarize data and then bind it.\n",
      "\n",
      "``` r\n",
      "map_res <- map(names(M)[names(M) != \"Sample\"], function(i){\n",
      "  res <- shapiro.test(M[[i]])\n",
      "\n",
      "  return(\n",
      "    list(\n",
      "    mrna = i,\n",
      "    p = res$p.value\n",
      "    )\n",
      "  )\n",
      "})\n",
      "\n",
      "shapiro_res <- do.call(rbind, map_res)\n",
      "```\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-11-20\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  For all you classics fiends out there, R has a convenience function just for you! (As long as your numbers aren't too big)\n",
      "\n",
      "``` r\n",
      "> as.numeric(as.roman(\"MCXXIII\"))\n",
      "[1] 1123\n",
      "> as.roman(1123)\n",
      "[1] MCXXIII\n",
      "> as.roman(11234)\n",
      "[1] <NA>\n",
      "```\n",
      "\n",
      "<https://twitter.com/geokaramanis/status/1327286201443905538|source>\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-12-7\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Get ready to celebrate in the streets: native pipes and terse lambdas are coming to R!\n",
      "\n",
      "> *R* now provides a simple native pipe syntax `|>` as well as a shorthand notation for creating functions, e.g. `\\(x) x + 1` is parsed as `function(x) x + 1`. \n",
      "<https://cran.r-project.org/doc/manuals/r-devel/NEWS.html>\n",
      "\n",
      "\n",
      "2020-12-7\n",
      "David Schulz\n",
      "I am a little torn though.  I LOVE me a terse lambda.\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-12-9\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Check out `DiagrammeR` (or mermaid) if you need clean easy flow diagrams. I find they're not to hard to make and _even easier_ to forget that you've made them.\n",
      "\n",
      "\n",
      "``` r\n",
      "DiagrammeR::grViz(\"digraph {\n",
      "graph [layout = dot]\n",
      "\n",
      "# define the global styles of the nodes. We can override these in box if we wish\n",
      "node [shape = circle, style = filled, fillcolor = LightSteelBlue]\n",
      "\n",
      "data1 [label = 'Input', shape = folder, fillcolor = Beige]\n",
      "\n",
      "glmnet [label = 'Lasso \n",
      "Regression', shape = box, fillcolor = Linen]\n",
      "mnnet [label = 'Mulitnomial \n",
      "Neural \n",
      "Network', shape = box, fillcolor = Linen]\n",
      "nnet [label = 'Neural \n",
      "Network', shape = box, fillcolor = Linen]\n",
      "knn [label = 'k-Nearest \n",
      "Neighbor', shape = box, fillcolor = Linen]\n",
      "ranger [label = 'Random \n",
      "Forest', shape = box, fillcolor = Linen]\n",
      "svml [label = 'SVM \n",
      "Linear', shape = box, fillcolor = Linen]\n",
      "svmr [label = 'SVM \n",
      "Radial', shape = box, fillcolor = Linen]\n",
      "\n",
      "data2 [label = '5-fold CV \n",
      "Accuracy', shape = folder, fillcolor = Beige]\n",
      "\n",
      "# edge definitions with the node IDs\n",
      "data1 -> {glmnet mnnet nnet knn ranger svml svmr} -> data2\n",
      "{alpha lambda} -> glmnet\n",
      "decay -> mnnet\n",
      "{size decay} -> nnet\n",
      "k -> knn\n",
      "{mtry splitrule minNodeSize} -> ranger\n",
      "cost -> svml\n",
      "sigma -> svmr\n",
      "}\")\n",
      "```\n",
      "\n",
      "![image (15).png](image%20(15).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-12-18\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  I just ran into the same issue <@U010N31RYMV> described after updating R on OSX —  none of the libraries are associated with the new version. I tested and abandoned directly copying the libraries over in favor programmatic reinstallation. The downside to this is that it’s slower. The upside is that if you just copy them, R will ask you to update the packages anyway.\n",
      "\n",
      "This won’t work for libraries that aren’t on CRAN but drastically reduces the number of libraries you’re installing by hand. In my case this took care of all but about 3% of the libraries I had installed for 3.6.\n",
      "\n",
      "\n",
      "``` r\n",
      "all_packages <- list.files(\"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/\")\n",
      "installed_packages <- list.files(\"/Library/Frameworks/R.framework/Versions/4.0/Resources/library/\")\n",
      "all_packages <- all_packages[!(all_packages %in% installed_packages)]\n",
      "\n",
      "options(install.packages.compile.from.source = \"always\")\n",
      "\n",
      "for (package in all_packages){\n",
      "  try(install.packages(package))\n",
      "}\n",
      "\n",
      "options(install.packages.compile.from.source = \"interactive\")\n",
      "```\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2020-12-22\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  You can set ggplot's font using the `theme` function. Particularly if combined with functions from `ggthemes` or `ggsci` you can get very pleasing visualizations quickly. Beyond accessing fonts already on your system you can import and fonts with minimal hassle.\n",
      "\n",
      "e.g. to get the font <https://fonts.google.com/specimen/Metal+Mania?sidebar.open=true&amp;selection.family=JetBrains+Mono:wght@100&amp;query=metal|Metal Mania> :metal: ready to use one might run:\n",
      "\n",
      "``` r\n",
      "library(showtext)\n",
      "font_add_google(name = \"Metal Mania\", family = \"Metal+Mania\")\n",
      "```\n",
      "\n",
      "\n",
      "``` r\n",
      "library(palmerpenguins)\n",
      "library(tidyverse)\n",
      "library(ggthemes)\n",
      "library(patchwork) # for adding together plots at the end\n",
      "library(extrafont)\n",
      "# font_import()) # <--- run this once\n",
      "loadfonts(device = \"win\", quiet = TRUE) # <--- run this once per session\n",
      "# extrafont::fonts() # see fonts that are available\n",
      "\n",
      "plt1 <- palmerpenguins::penguins %>%\n",
      "  filter(!<http://is.na|is.na>(sex)) %>%\n",
      "  mutate(sex = case_when(sex == \"male\" ~ \"m\",\n",
      "                         sex == \"female\" ~ \"f\")) %>% \n",
      "  ggplot(aes(sex, body_mass_g, fill = species, group = interaction(species, sex)))+\n",
      "  geom_boxplot()+\n",
      "  ggthemes::scale_fill_colorblind()+\n",
      "  ggthemes::theme_clean()+\n",
      "  theme(legend.position = \"\")+\n",
      "  facet_grid(.~species)+\n",
      "  labs(title = \"Default\")\n",
      "\n",
      "plt2 <- plt1+\n",
      "  theme(text = element_text(family = \"Consolas\"))+\n",
      "  labs(title = \"Consolas\")\n",
      "\n",
      "plt3 <- plt1+\n",
      "  theme(text = element_text(family = \"Garamond\"))+\n",
      "  labs(title = \"Garamond\")\n",
      "\n",
      "plt1 + plt2 + plt3\n",
      "```\n",
      "\n",
      "\n",
      "![image (17).png](image%20(17).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2021-2-2\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Anyone run into issues with `corrplot::corrplot()`  cutting off the title?\n",
      "![image (18).png](image%20(18).png)\n",
      "\n",
      "\n",
      "\n",
      "2021-2-2\n",
      "`ggcorrplot` makes okay plots with ggplot2's logic. Not as clean as the above but it'll work with `patchwork`  and `cowplot` . Unfortunately, `scale_colour_stepsn`  doesn't override the  scaling.\n",
      "\n",
      "``` r\n",
      "library(ggcorrplot)\n",
      "\n",
      "p.mat <- cor_pmat(cor_df)\n",
      "ggcorrplot(cor(cor_df, use = \"pairwise.complete.obs\"), \n",
      "           p.mat = p.mat,\n",
      "           insig = \"blank\",\n",
      "           type = \"upper\",\n",
      "           outline.col = \"white\",\n",
      "           colors = RColorBrewer::brewer.pal(n = 9, name = \"PuOr\")[c(1,5,9)]\n",
      "           )+\n",
      "  labs(title = \"Brian_AP_Delayed\")\n",
      "```\n",
      "\n",
      "\n",
      "![image (19).png](image%20(19).png)\n",
      "\n",
      "2021-2-2\n",
      "`ggcorrplot` appears to call internal functions which makes modifying it quickly impractical (one would probably be best forking the package and modifying that). I think I have a workaround that gets the same binning behavior:\n",
      "\n",
      "After the significance matrix (`p.mat`) is generated overwrite the correlation matrix with the middle value of each desired bin.\n",
      "\n",
      "``` r\n",
      "          bkkca      cav1      cav2\n",
      "bkkca 1.0000000 0.3452702 0.5603564\n",
      "cav1  0.3452702 1.0000000 0.7880727\n",
      "cav2  0.5603564 0.7880727 1.0000000\n",
      "> # bin the correlations so there are fewer colors used in the figure\n",
      "> cor_bins <- seq(-1, 1, length.out = 9)\n",
      "> for (i in 1:(length(cor_bins)-1)){\n",
      "+   test[test > cor_bins[i] &amp; test < cor_bins[i+1]] <- ((cor_bins[i] + cor_bins[i+1])/2)\n",
      "+ }\n",
      "> test\n",
      "      bkkca  cav1  cav2\n",
      "bkkca 1.000 0.375 0.625\n",
      "cav1  0.375 1.000 0.875\n",
      "cav2  0.625 0.875 1.000\n",
      "```\n",
      "\n",
      "Here this makes very slight changes to the plot. (legend dropped to not imply a continuous fill)\n",
      "![image (20).png](image%20(20).png)\n",
      "\n",
      "2021-2-2\n",
      "Last update, this is harder to read up will use the more extreme value to get closer to `corrplot`\n",
      "\n",
      "\n",
      "``` r\n",
      "test <- seq(-1, 1, length.out = 5)+.0000001\n",
      "test\n",
      "#-0.9999999 -0.4999999  0.0000001  0.5000001  1.0000001\n",
      "for (i in 1:(length(cor_bins)-1)){\n",
      "  # test[test > cor_bins[i] &amp; test < cor_bins[i+1]] <- (cor_bins[i] + cor_bins[i+1])\n",
      "  test[test > cor_bins[i] &amp; test < cor_bins[i+1]] <-   cor_bins[c(i, (i+1))[which.max(abs(cor_bins[i:(i+1)]))]]\n",
      "}\n",
      "test\n",
      "#-1.00 -0.50  0.25  0.75  1.00\n",
      "```\n",
      "\n",
      "\n",
      "![image (21).png](image%20(21).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2021-2-3\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  <@U0103JSQYLB> and I just talked through how one might compare two sets of p values. We're thinking about the following approach and wanted to see if anyone can see a flaw in this approach or has other ideas.\n",
      "\n",
      "Setup:\n",
      "You have two replicates of an experiment (`r1, r2`). In each experiment you measured three mRNAs (_`a, b, c`_) in control and treatment (`c, t`). You want to know if the same trends in `r1` show up in `r2` but there is a batch effect that will prevent comparing them directly (e.g. you can't run a t test on `r1 _a_ c` and `r2 _a_ c` )\n",
      "\n",
      "Proposed Solution:\n",
      "1. Compare each mRNA within a replicate and note the sign of change and if the p value reached a pre-determined cutoff\n",
      "\n",
      "``` r\n",
      "rep  |mrna |sign |pval |sig  |\n",
      "r1   | a   | -   |0.04 |1    |\n",
      "r1   | b   | +   |0.10 |0    |\n",
      "...  |     |     |     |     |\n",
      "r2   | c   | -   |0.02 |1    |\n",
      "```\n",
      "\n",
      "2. Multiply the sign by the significance code so that -1 = \"significant decrease\", 0 = \"no significant change\", +1 = \"significant increase\"\n",
      "\n",
      "``` r\n",
      "rep  |mrna |sign |pval |sig  |sxp  |\n",
      "r1   | a   | -   |0.04 |1    |+1   |\n",
      "r1   | b   | +   |0.10 |0    |0    |\n",
      "...  |     |     |     |     |     |\n",
      "r2   | c   | -   |0.02 |0    |-1   |\n",
      "```\n",
      "\n",
      "3. Reshape these as two vectors and treat them as categorical data. Then compare the \"assignment\" between these two lists using a jaccard index as if we were comparing an assignment from clustering against reality.\n",
      "\n",
      "``` r\n",
      "r1 <- as.character(c(1, 0, 0))\n",
      "r2 <- as.character(c(0, 0, -1))\n",
      "jaccard(r1, r2)\n",
      "```\n",
      "\n",
      "4. Use resampling to find an empirical p value for this observed jaccard index.\n",
      "\n",
      "Does that seem reasonable? Is there another way you would go about it?\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2021-2-10\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Here's an implementation for two sets of correlations. Here we bin the correlations into 5 bins use a jaccard index to assess whether the bin assignments are the same for both datasets (Brian's and mine). To confirm that the measured jaccard index (0.23) isn't anything to write home about we can generate  an empirical p value (ep = 0.13).\n",
      "\n",
      "\n",
      "``` r\n",
      "# cor_comp_df\n",
      "#\n",
      "#    Source Time     x     y        Corr\n",
      "#    <fct>  <fct>    <chr> <chr>   <dbl>\n",
      "#  1 Brian  Baseline bkkca cav1    0.441\n",
      "#  2 Brian  Baseline bkkca cav2    0.476\n",
      "#  3 Brian  Baseline bkkca inx1    0.435\n",
      "#  4 Brian  Baseline bkkca inx2    0.159\n",
      "#  5 Brian  Baseline bkkca inx3   -0.174\n",
      "#  6 Brian  Baseline bkkca inx4   -0.167\n",
      "\n",
      "n_bins <- 5\n",
      "\n",
      "temp <- cor_comp_df %>% \n",
      "  mutate(Bins = cut(Corr, breaks = seq(-1, 1, length.out = n_bins))) %>% \n",
      "  select(-Corr) %>% \n",
      "  pivot_wider(names_from = \"Source\", values_from = \"Bins\")\n",
      "\n",
      "# temp\n",
      "#\n",
      "#   Time     x     y     Brian    Daniel  \n",
      "#   <fct>    <chr> <chr> <fct>    <fct>   \n",
      "# 1 Baseline bkkca cav1  (0,0.5]  (0,0.5] \n",
      "# 2 Baseline bkkca cav2  (0,0.5]  (0,0.5] \n",
      "# 3 Baseline bkkca inx1  (0,0.5]  (0.5,1] \n",
      "# 4 Baseline bkkca inx2  (0,0.5]  (0.5,1] \n",
      "# 5 Baseline bkkca inx3  (-0.5,0] (0.5,1] \n",
      "# 6 Baseline bkkca inx4  (-0.5,0] (-0.5,0]\n",
      "\n",
      "\n",
      "library('clusteval')\n",
      "obs_jaccard <- cluster_similarity(temp$Brian, temp$Daniel, similarity=\"jaccard\")  \n",
      "\n",
      "# 0.2304234\n",
      "\n",
      "null_jaccard <- map(1:10000, function(i){\n",
      "  cluster_similarity(sample(temp$Brian, replace = F), \n",
      "                     temp$Daniel, similarity=\"jaccard\")\n",
      "  }) %>% \n",
      "  unlist()\n",
      "\n",
      "\n",
      "temp <- with(density(null_jaccard), data.frame(x, y))\n",
      "temp <- temp %>% mutate(xmax = max(x),\n",
      "                obs = obs_jaccard)\n",
      "\n",
      "ggplot(data = temp, aes(x = x, y = y))+\n",
      "  geom_line()+\n",
      "  geom_vline(xintercept = obs_jaccard)+\n",
      "  geom_ribbon(data = temp[temp$x > temp$obs, ], \n",
      "              aes(xmin = obs, xmax = xmax, ymin = 0, ymax = y))+\n",
      "  labs(subtitle = paste(\"empirical p=\", as.character(mean(null_jaccard >= obs_jaccard))))\n",
      "```\n",
      "\n",
      "\n",
      "![image (22).png](image%20(22).png)\n",
      "\n",
      "2021-2-10\n",
      "It's worth generating an empirical p value for each comparison you're making. For example here I'm comparing the results of an experiment replicate. Each dependent variable is assigned a group based on if one would conclude it there was a difference (0 or 1) between groups and the sign of that difference (+ or -). Seeing a Jaccard index of 0.61 (out of 1) we might conclude we replicated most of the findings. _However,_ the empirical p value is 1 because most of the comparisons were non-significant in both groups resulting in a high floor for the index.\n",
      "![image (23).png](image%20(23).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2021-2-21\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  I think I have a solution to get decent enough dendrograms without fussing with base graphics.\n",
      "\n",
      "The overview of my workaround is to cluster with `pvclust`, extract `$hclust` , plot it as a dendrogram, coerce into a ggplot.  This makes it easy enough to replicate the functionality of the `colored_bars()`  function by making additional plots.  The function below makes a few plots in addition to the dendrogram. If you end up working with base graphics anyway, `dendextend` is still worth a look.\n",
      "\n",
      "Here's an example:\n",
      "\n",
      "``` r\n",
      "# needed \n",
      "library(pvclust)\n",
      "library(tidyverse)\n",
      "library(dendextend) # for color_labels\n",
      "library(ggnewscale) # to accommodate two fill scales \n",
      "\n",
      "# recommended\n",
      "# install.packages(\"palmerpenguins\")\n",
      "library(palmerpenguins)\n",
      "library(patchwork)\n",
      "library(scales) # for overiding scientific notation on dendrogram y axis \n",
      "\n",
      "# Make a demo dataset\n",
      "tux <- select(palmerpenguins::penguins, \n",
      "              species,\n",
      "              bill_length_mm, bill_depth_mm, \n",
      "              flipper_length_mm, body_mass_g) \n",
      "\n",
      "tux <- tux[complete.cases(tux), ]\n",
      "\n",
      "set.seed(54646)\n",
      "tux <- tux[sample(1:nrow(tux), 30), ] # for faster demo clustering\n",
      "\n",
      "# Example use\n",
      "o <- \n",
      "  mk_hclust_plts(\n",
      "    df = mutate(tux, uid = paste(seq(1, nrow(tux)), species, sep = \"-\")),\n",
      "    cluster_by = c(\"bill_length_mm\", \"bill_depth_mm\", \n",
      "                   \"flipper_length_mm\", \"body_mass_g\"),\n",
      "    uid_col = \"uid\",\n",
      "    n_clusters = 3,\n",
      "    true_groups = \"species\",\n",
      "    true_colors = RColorBrewer::brewer.pal(3, \"Set2\"),\n",
      "    cluster_colors = RColorBrewer::brewer.pal(3, \"Set1\") \n",
      "  )\n",
      "\n",
      "\n",
      "# Patchwork to arrange the output plots\n",
      "(o$dendrogram_both+\n",
      "    scale_y_continuous(limits = c(-.0001, 0.00022), labels = scales::comma)\n",
      ")/ \n",
      "  (o$group_compare_tile+\n",
      "     # lims(y =  c(2, -2))+ # y axis can be flipped like so\n",
      "     theme(legend.position = \"\")\n",
      "  ) / \n",
      "  (o$heatmap_raw + theme(legend.position = \"right\")) / \n",
      "  (o$heatmap_z + theme(legend.position = \"right\")) + \n",
      "  patchwork::plot_layout(heights = c(5, .3, 1.25, 1.25))\n",
      "\n",
      "\n",
      "# example 2\n",
      "\n",
      "# o <- \n",
      "# mk_hclust_plts(\n",
      "#   df = mutate(iris, uid = paste(seq(1, nrow(iris)), Species, sep = \"-\")),\n",
      "#   cluster_by = c(\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"),\n",
      "#   uid_col = \"uid\",\n",
      "#   n_clusters = 3,\n",
      "#   true_groups = \"Species\",\n",
      "#   true_colors = RColorBrewer::brewer.pal(3, \"Set2\"),\n",
      "#   cluster_colors = RColorBrewer::brewer.pal(3, \"Set1\") \n",
      "# )\n",
      "```\n",
      "\n",
      "ps, it's worth checking your code on sample datasets (`penguins`, `iris`, `mpg`, etc. ). That'll help iron out weird behavior sooner rather than later.\n",
      "![image (25).png](image%20(25).png)\n",
      "\n",
      "2021-2-21\n",
      "Daniel\n",
      "And here's the source for the function itself.\n",
      "\n",
      "\n",
      "2021-2-21\n",
      "Daniel\n",
      "Edit: The original function here depended on the factor levels of the clusters and true groups to make the color's consistent between plots (e.g. factors ordered abcdABCD not aAbBcCdD). This breaks down with some cases (e.g. if you start group names with a number (e.g. 0hours)). The below edit uses `ggnewscale`  to fix this.\n",
      "\n",
      "<https://github.com/eliocamp/ggnewscale>\n",
      "\n",
      "\n",
      "``` r\n",
      "mk_hclust_plts <- function(\n",
      "  df = unite(M_winxiqr, uid, Experiment, Cell, sep = \"-\"),\n",
      "  cluster_by = c(\"vrest\", \"r11\", \"r1\", \"Ihtk.0\", \"Ihtk.Slope\", \"Ia.0\", \"Ia.Slope\"),\n",
      "  uid_col = \"uid\",\n",
      "  n_clusters = 3,\n",
      "  true_groups = \"Condition\",\n",
      "  true_colors = RColorBrewer::brewer.pal(3, \"Set2\"),\n",
      "  cluster_colors = RColorBrewer::brewer.pal(3, \"Set1\")\n",
      "){\n",
      "  df <- as.data.frame(df) \n",
      "  \n",
      "  if (!exists(\"cluster_colors\")){\n",
      "    cluster_colors = rainbow(n_clusters)\n",
      "  }\n",
      "  ## prep\n",
      "  # move uid to rowname\n",
      "  row.names(df) <- df[[uid_col]]\n",
      "  df_groups <- select(df, all_of(true_groups))\n",
      "  df <- df[, cluster_by]\n",
      "  \n",
      "  ## Cluster\n",
      "  cluster <- pvclust(t(df),\n",
      "                     method.hclust = \"ward.D2\",\n",
      "                     method.dist = \"correlation\",\n",
      "                     use.cor = \"pairwise.complete.obs\")\n",
      "  \n",
      "  \n",
      "  ## make dendrogram  ####\n",
      "  dend <- cluster$hclust %>% \n",
      "    as.dendrogram() \n",
      "  \n",
      "  # iteratively coloring the labels is a workaround to get the \"true\" groups shown\n",
      "  dend_labs <- rownames_to_column(df_groups, var = \"rownames\")[, ]\n",
      "  dend_labs <- full_join(data.frame(rownames = labels(dend)), dend_labs)\n",
      "  for(i in seq_along(unique(df_groups[[true_groups]]))){\n",
      "    true_group <- unique(df_groups[[true_groups]])[i]\n",
      "    true_color <- true_colors[i]\n",
      "    \n",
      "    dend <- dend %>% \n",
      "      dendextend::color_labels(\n",
      "        col = true_color, \n",
      "        labels = dend_labs[dend_labs[[true_groups]] == true_group, \"rownames\"]) \n",
      "    \n",
      "    \n",
      "  }\n",
      "  \n",
      "  dend <- dend %>% \n",
      "    set(\"branches_k_color\", \n",
      "        k = n_clusters, \n",
      "        value = cluster_colors\n",
      "    ) %>% \n",
      "    set(\"branches_lwd\", 0.7) %>%\n",
      "    set(\"labels_cex\", 0.6) \n",
      "\n",
      "  dend_cluster_only <- dend %>% \n",
      "    set(\"labels_colors\",\n",
      "        k = n_clusters,\n",
      "        value = cluster_colors) %>%\n",
      "    as.ggdend()\n",
      "  \n",
      "  \n",
      "  dend <- dend %>% \n",
      "    as.ggdend()\n",
      "  \n",
      "  \n",
      "  \n",
      "  plt_dend_cluster_only <- ggplot(dend_cluster_only)+\n",
      "    theme(axis.ticks.y = element_line(),\n",
      "          axis.text.y = element_text(),\n",
      "          axis.line.y = element_line())\n",
      "  \n",
      "  \n",
      "  plt_dend <- ggplot(dend)+\n",
      "    theme(axis.ticks.y = element_line(),\n",
      "          axis.text.y = element_text(),\n",
      "          axis.line.y = element_line())  \n",
      "  \n",
      "\n",
      "  ## Add reality ribbon with or without clustering result ####\n",
      "  groups_to_plt <- full_join(\n",
      "    as.data.frame(dend$labels),\n",
      "    rownames_to_column(var = \"label\", df_groups))\n",
      "  \n",
      "  plt_grouping <- groups_to_plt %>% \n",
      "    ggplot(aes_string(x=\"x\", y=\"0\", fill = true_groups))+\n",
      "    geom_tile()+\n",
      "    scale_fill_manual(values = true_colors)+\n",
      "    theme_void()+\n",
      "    labs(x = \"\", y = \"\")+\n",
      "    theme(legend.position = \"left\")\n",
      "  \n",
      "  plt_grouping_contrast <- ggplot()+\n",
      "    geom_tile(data = groups_to_plt, aes_string(x=\"x\", y=\"0.5\", fill = true_groups))+\n",
      "    scale_fill_manual(values = true_colors)+\n",
      "    \n",
      "    ggnewscale::new_scale(\"fill\") +\n",
      "    geom_tile(data = data.frame(x = seq_along(dend_cluster_only$labels$col),\n",
      "                                cluster_groups = as.character(as.numeric(as.factor(dend_cluster_only$labels$col)))\n",
      "    ),\n",
      "    aes_string(x=\"x\", y= \"-0.5\", fill = \"cluster_groups\"),\n",
      "    )+\n",
      "    scale_fill_manual(values = cluster_colors)+\n",
      "    \n",
      "    theme_void()+\n",
      "    labs(x = \"\", y = \"\")+\n",
      "    theme(legend.position = \"left\")\n",
      "  \n",
      "  \n",
      "  ## Add heatmap  ####\n",
      "  data_to_plt <- full_join(\n",
      "    as.data.frame(dend$labels),\n",
      "    rownames_to_column(var = \"label\", df)) \n",
      "  \n",
      "  data_to_plt <- \n",
      "    data_to_plt %>% \n",
      "    gather(\"key\", \"value\", \n",
      "           names(data_to_plt)[\n",
      "             !(names(data_to_plt) %in% c(\"x\", \"y\", \n",
      "                                         \"label\", \"col\", \"cex\", \n",
      "                                         true_groups))\n",
      "           ])\n",
      "  \n",
      "  plt_heatmap_raw <- data_to_plt %>% \n",
      "    ggplot(aes(x, \n",
      "               y = key, \n",
      "               fill = value))+\n",
      "    geom_tile()+\n",
      "    scale_fill_viridis_c()+\n",
      "    labs(x = \"\", y = \"\")+\n",
      "    theme(panel.background = element_blank(),\n",
      "          axis.ticks.x = element_blank(),\n",
      "          axis.text.x = element_blank(),\n",
      "          legend.position = \"left\")\n",
      "  \n",
      "  \n",
      "  plt_heatmap_z <- data_to_plt %>% \n",
      "    group_by(key) %>% \n",
      "    mutate(mean = mean(value, na.rm = T),\n",
      "           sd = sd(value, na.rm = T)) %>% \n",
      "    mutate(value = ((value - mean)/sd)) %>% # Now Z scores\n",
      "    ggplot(aes(x, \n",
      "               y = key, \n",
      "               fill = value))+\n",
      "    geom_tile()+\n",
      "    scale_fill_viridis_c()+\n",
      "    labs(x = \"\", y = \"\")+\n",
      "    theme(panel.background = element_blank(),\n",
      "          axis.ticks.x = element_blank(),\n",
      "          axis.text.x = element_blank(),\n",
      "          legend.position = \"left\")\n",
      "  \n",
      "  \n",
      "  ## Return plots, manually tweak layout  ####\n",
      "  return(\n",
      "    list(\n",
      "      pvclust_out = cluster,\n",
      "      dendrogram_clusters = plt_dend_cluster_only,\n",
      "      dendrogram_both = plt_dend,\n",
      "      group_tile = plt_grouping,\n",
      "      group_compare_tile = plt_grouping_contrast,\n",
      "      heatmap_raw = plt_heatmap_raw,\n",
      "      heatmap_z = plt_heatmap_z\n",
      "    )\n",
      "  )\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "2021-2-21\n",
      "David Schulz\n",
      "I am going to have to find a reason to play around with this, because it looks great.  Thanks!  How can we ensure the world can benefit? Is this new and exciting to others as well?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2021-2-22\n",
      "Daniel\n",
      "It's potentially worth making available online but I don't know that it's all together too useful. The components of it make for a good starting place to write from but the function itself is fairly inflexible (e.g. in terms of clustering method and tree aesthetics). Where I think it could work nicely is in a sort of \"lab reference\" with recommended/first pass solutions to needs that come up with the sort of data we collect.\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2021-3-3\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Does anyone have an effective way to deduplicate/shave correlation data frames prior to running a KS test? An inelegant workaround seems to be to order the data frame by correlation and retain every other row. Here's some example data either with or without these duplications.\n",
      "![image (26).png](image%20(26).png)\n",
      "![image (27).png](image%20(27).png)\n",
      "\n",
      "2021-3-3\n",
      "Daniel\n",
      "I also thought about using a mutate and ifelse to paste the x/y values into an alphabetical identifier (e.g. shal, bkkca, 0.## would become bkkca-shal, 0.##) but doing that seems like a huge pain.\n",
      "\n",
      "2021-3-3\n",
      "David Schulz\n",
      "I think this is code you generated for me, no?\n",
      "\n",
      "2021-3-3\n",
      "David Schulz\n",
      "\n",
      "``` r\n",
      "temp.list <- map(unique(M$Cell), function(i){\n",
      "  M %>% \n",
      "    filter(Cell == i) %>% \n",
      "    select(-c(\"Cell\")) %>% \n",
      "    correlate(use = \"pairwise.complete.obs\", method = \"pearson\") %>% \n",
      "    shave() %>% # Prevent double counting of correlations\n",
      "    mutate(Cell = i)\n",
      "})\n",
      "```\n",
      "\n",
      "\n",
      "2021-3-3\n",
      "David Schulz\n",
      "I'll put the whole thing in here, just to make sure.  Either you generated this for me (which it has your fingerprints on it), or I pilfered this from somewhere.\n",
      "\n",
      "2021-3-3\n",
      "David Schulz\n",
      "\n",
      "``` r\n",
      "\n",
      "{r}\n",
      "library(corrr)\n",
      "M <- STGGOI\n",
      "\n",
      "temp.list <- map(unique(M$Cell), function(i){\n",
      "  M %>% \n",
      "    filter(Cell == i) %>% \n",
      "    select(-c(\"Cell\")) %>% \n",
      "    correlate(use = \"pairwise.complete.obs\", method = \"pearson\") %>% \n",
      "    shave() %>% # Prevent double counting of correlations\n",
      "    mutate(Cell = i)\n",
      "})\n",
      "\n",
      "\n",
      "\n",
      "M <- do.call(rbind, temp.list)\n",
      "M <- M %>% \n",
      "  gather(colname, cor, names(select(M, -c(\"rowname\", \"Cell\")))) \n",
      "\n",
      "#M <- subset(M, cor >= 0.5)\n",
      "plot_ecdf_ks <- function(\n",
      "  df = temp.df,\n",
      "  data.col = \"cor\",\n",
      "  group.col = \"data\",\n",
      "  group1 = \"0\",\n",
      "  group2 = \"24\",\n",
      "  colors = c(\"#4d4d4d\", \n",
      "             #\"#67a9cf\", \n",
      "             \"#1c9099\")) {\n",
      "  \n",
      "  # Adapted from:\n",
      "  # <https://rpubs.com/mharris/KSplot>\n",
      "  df <- filter(df, df[[group.col]] %in% c(group1, group2))\n",
      "  \n",
      "  df[df[[group.col]] == group1, data.col]\n",
      "  \n",
      "  \n",
      "  data1 <- unlist(df[df[[group.col]] == group1, data.col])\n",
      "  data2 <- unlist(df[df[[group.col]] == group2, data.col])\n",
      "  \n",
      "  ecdf1 <- ecdf(data1)\n",
      "  ecdf2 <- ecdf(data2)\n",
      "  \n",
      "  # used to get the most extreme difference between the two samples\n",
      "  MostExtremeDiff <- seq(min(data1, data2, na.rm = T), max(data1, data2, na.rm = T), length.out = length(data1))\n",
      "  x0 <- MostExtremeDiff[which(abs(ecdf1(MostExtremeDiff) - ecdf2(MostExtremeDiff)) == \n",
      "                                max(abs(ecdf1(MostExtremeDiff) - ecdf2(MostExtremeDiff))))]\n",
      "  y0 <- ecdf1(x0)\n",
      "  y1 <- ecdf2(x0)\n",
      "  \n",
      "  graph.df <- data.frame(data1, data2) %>% gather(Condition, Value, 1:2)\n",
      "  graph.df[graph.df$Condition == \"data1\", \"Condition\"] <- group1\n",
      "  graph.df[graph.df$Condition == \"data2\", \"Condition\"] <- group2\n",
      "  \n",
      "  # Run two sided KS test on data\n",
      "  test.res <- ks.test(data1, data2)\n",
      "  \n",
      "  plt <- \n",
      "    ggplot(graph.df)+\n",
      "    geom_segment(aes(x = x0[1], y = y0[1], xend = x0[1], yend = y1[1]),\n",
      "                 linetype = \"dashed\", color = \"black\", size = 1)+\n",
      "    geom_point(aes(x = x0[1] , y= y0[1]), color=\"black\", size=2) +\n",
      "    geom_point(aes(x = x0[1] , y= y1[1]), color=\"black\", size=2) +\n",
      "    stat_ecdf(aes(x = Value, group = Condition, color = Condition))+\n",
      "    labs(x = \"Sample\", \n",
      "         y = \"ECDF\", \n",
      "         title = paste(\"K-S Test\", as.character(group1), \"vs\", as.character(group2), \n",
      "                       \"\n",
      "p-value:\", as.character(test.res$p.value, digits = 4)))+\n",
      "    theme_minimal()+\n",
      "    theme(legend.position = \"bottom\")+\n",
      "    scale_color_manual(values = colors)#+\n",
      "    # theme(text=element_text(family=\"Calibri Light\", size=14)) \n",
      "  \n",
      "  return(plt)\n",
      "  \n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "``` r\n",
      "\n",
      "\n",
      "2021-3-3\n",
      "Daniel\n",
      "Yeah I think this is from me. `shave`  is from `library(corrr)`  and achieves this nicely. I was thinking after the data's in long format, but the solution may just be to do it on the front end instead of after it's long.\n",
      "\n",
      "2021-3-3\n",
      "David Schulz\n",
      "So in other words I answered your question by facilitating a conversation between you and yourself. You're welcome.  :slightly_smiling_face:\n",
      "\n",
      "2021-3-3\n",
      "Daniel\n",
      "I appreciate it.\n",
      "\n",
      "For anyone using this in the future, `shave`  doesn't work with dataframes or the output of `cor`  so you'll need to run `as.data.frame` after shaving it.\n",
      "\n",
      "2021-3-3\n",
      "Daniel\n",
      "Found some code I wrote to do this following `cor`.\n",
      "This is probably only worth doing this way if you're calculating p values (for corplot) since the same strategy can be applied to a `p.mat`.\n",
      "\n",
      "\n",
      "```\n",
      "  cor_df <- cor(cor_df, use = \"pairwise.complete.obs\")\n",
      "  \n",
      "  # Shave to diagonal\n",
      "  for (j in seq(1, nrow(cor_df))){\n",
      "    cor_df[j, 1:j] <- NA\n",
      "  }\n",
      "``` r\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2021-3-5\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Two tricks today:\n",
      "1. Scale fill functions can accept breaks and limit arguments so you don't have to use hacky workarounds like binning the data before plotting (which is what I usually do).\n",
      "2. `library(ggtext)` lets you render markdown within plots (e.g. for those pesky mRNAs)\n",
      "\n",
      "```\n",
      "> df\n",
      "# A tibble: 540 x 4\n",
      "   term   Condition term2    Cor\n",
      "   <chr>  <chr>     <chr>  <dbl>\n",
      " 1 bkkca  0h        vrest -0.420\n",
      " 2 cav1   0h        vrest -0.252\n",
      " 3 cav2   0h        vrest -0.276\n",
      " 4 inx1   0h        vrest -0.313\n",
      " 5 inx2   0h        vrest -0.327\n",
      "``` r\n",
      "\n",
      "Before:\n",
      "\n",
      "```\n",
      "df %>% \n",
      "  ggplot(aes(term, term2, fill = Cor))+\n",
      "  geom_tile()+\n",
      "  labs(x= \"mRNA\", y = \"\")+\n",
      "  scale_fill_distiller(palette = \"PuOr\")+\n",
      "  coord_fixed()\n",
      "``` r\n",
      "\n",
      "After:\n",
      "\n",
      "```\n",
      "library(ggtext)\n",
      "library(glue)\n",
      "\n",
      "df %>% \n",
      "  mutate(term = glue((\"<i>{term}</i>\"))) %>%  \n",
      "  ggplot(aes(term, term2, fill = Cor))+\n",
      "  geom_tile()+\n",
      "  labs(x= \"mRNA\", y = \"\")+\n",
      "  \n",
      "  theme(axis.text.x = element_markdown(angle = 45))+ # <-- Note that we have element_markdown not element_text\n",
      "  \n",
      "  scale_fill_stepsn(\n",
      "    colors=RColorBrewer::brewer.pal(n = 8, name = \"PuOr\"),\n",
      "    na.value = \"transparent\",\n",
      "    breaks=round(seq(-1, 1, length.out = 8), digits = 2),\n",
      "    limits=c(-1,1)\n",
      "  )+\n",
      "  coord_fixed()\n",
      "``` r\n",
      "\n",
      "![image (28).png](image%20(28).png)\n",
      "![image (29).png](image%20(29).png)\n",
      "\n",
      "2021-3-5\n",
      "Daniel\n",
      "<https://github.com/wilkelab/ggtext>\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2021-3-9\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  Another useful trick is to pass expressions into ggplot. Here I've used the following as arguments in `labs()`.\n",
      "\n",
      "\n",
      "```\n",
      "c(\"r11\", \"r1\", \"Ihtk.0\", \"Ihtk.Slope\", \"Ia.0\", \"Ia.Slope\", \"vrest\")\n",
      "c(expression(M~Omega), expression(M~Omega), \"nA\", expression(frac(nA, mV)), \"nA\", expression(frac(nA, mV)), \"mV\" )\n",
      "``` r\n",
      "\n",
      "\n",
      "![image (30).png](image%20(30).png)\n",
      "\n",
      "2021-3-9\n",
      "Daniel\n",
      "You can also do something like this `theme(plot.title = element_text(face=\"italic\"))`\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "2021-3-11\n",
      "Reordering a discrete axis in ggplot after generation a lot simpler than one might expect.  Rather than converting a character column to a factor (what if the data gets pivoted?), or using one column for the position and one for the labels, you can use `xlim` or `ylim`.\n",
      "\n",
      "```\n",
      "> mrna_cols # desired order\n",
      "# [1] \"nav\"    \"cav1\"   \"cav2\"   \"bkkca\"  \"shaker\" \"shal\"   \"shab\"   \"shaw1\" \n",
      "# [9] \"shaw2\"  \"inx1\"   \"inx2\"   \"inx3\"  \n",
      "\n",
      "o_mrna$heatmap_z / # ggplot object within a list\n",
      "o_mrna$heatmap_z+ylim(mrna_cols)\n",
      "``` r\n",
      "\n",
      "\n",
      "![image (31).png](image%20(31).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2021-3-23\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  R's distribution simulation functions (e.g. `dbinom`, `runif`) make it quick and easy to double check one's intuitions. For example, I'd been thinking that under H0 the distribution of correlations from normal samples should drop off sharply as you go away from 0 such that a shift in correlation from 0 -> 0.1 is much more likely than 0.8 -> 0.9.\n",
      "\n",
      "\n",
      "So I used `purrr::map()` to run a quick simulation. Here we simulate the null distribution based on 100,000 observations and compute the chance of a value being above 0.7. If it was uniform we would expect ~15% (.03/2) of the distribution to be here but end up with ~1.2% with the drop off.\n",
      "\n",
      "```\n",
      "set.seed(89745)\n",
      "cor_check <- map(1:100000, function(i){ \n",
      "  cor(rnorm(10), rnorm(10), method = \"pearson\")\n",
      "})\n",
      "cor_check <- data.frame(cor = do.call(rbind,  cor_check))\n",
      "ggplot(cor_check, aes(x = cor))+  geom_histogram(binwidth = 0.05)\n",
      "mean(cor_check$cor >= 0.7)*100\n",
      "# 1.227 Percent\n",
      "``` r\n",
      "\n",
      "\n",
      "![image (32).png](image%20(32).png)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2021-9-7\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  <https://github.com/seatgeek/fuzzywuzzy|https://github.com/seatgeek/fuzzywuzzy> this is a tool that isn’t necessary most of the time but when it is it can save a ton of time. It lets you do approximate string matching. I’ve used it for handling typos and differences in white space/ punctuation/ naming conventions in entry labels and it’s worked nicely. There’s a port for R and a few other languages too. \n",
      "\n",
      "2021-9-7\n",
      "Joe\n",
      "Thanks zombie Daniel \n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2022-5-31\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  ggplot tip: if you use an eight digit hex code for specifying a color value, the first two control transparency. Thus, you can set `fill` `=` `“#00000000”` in ggplot to get a boxplot with no fill.\n",
      "\n",
      "2022-5-31\n",
      "Here's the use case: points on top occlude the cross bar but box on top hides the observations. You could also do this by changing alpha but I think that will alter the lines as well.\n",
      "![Image from iOS](Image from iOS.jpg)\n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2023-5-23\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  R treats # as a comment in text files. \n",
      "\n",
      "A file I have (hapmap of snps) included one in a field of the header. If your look at the words on the first to lines with wc they will agree but R will fail to load the file. The solution is to pass in an explicit comment character like so `read.table(“snps.txt”, comment.char=‘’)`. \n",
      "\n",
      "---\n",
      "title: \"Placeholder\"\n",
      "author: \"Daniel Kick\"\n",
      "date: 2024-3-21\n",
      "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
      "categories: \n",
      "  - code\n",
      "  - beginner\n",
      "  - r\n",
      "draft: false\n",
      "editor: \n",
      "  markdown: \n",
      "    wrap: 72\n",
      "---\n",
      "  <https://blog.moertel.com/posts/2006-01-20-wondrous-oddities-rs-function-call-semantics.html|https://blog.moertel.com/posts/2006-01-20-wondrous-oddities-rs-function-call-semantics.html>\n",
      "\n",
      "This is the sort of thing you don’t realize until it would be _really_ useful to access the name of a variable or run text as if it were code. I think the most accessible example of R’s wizardry is in plotting- you pass variables (time, mv) to plot or ggplot instead of strings (“time”, “mv”) and magically you get axis labels. R gets access to the _value_ of a variable _*and*_ its name and no one notices because it just works. :exploding_head:  ```\n"
     ]
    }
   ],
   "source": [
    "post = posts[0]\n",
    "\n",
    "out = []\n",
    "\n",
    "for post in posts:\n",
    "  _ = post.split('\\n')\n",
    "  ts = _[0]\n",
    "  res = f\"\"\"---\n",
    "title: \"Placeholder\"\n",
    "author: \"Daniel Kick\"\n",
    "date: {ts}\n",
    "image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"\n",
    "categories: \n",
    "  - code\n",
    "  - beginner\n",
    "  - r\n",
    "draft: false\n",
    "editor: \n",
    "  markdown: \n",
    "    wrap: 72\n",
    "---\n",
    "  \"\"\"+'\\n'.join(_[2:] if _[1] == 'Daniel' else _[1:])\n",
    "  out.append(res)\n",
    "\n",
    "print('\\n\\n'.join(out))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c730d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d254a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-4-1\n",
      "Daniel\n",
      "You can keep your working `Rmd` easier to navigate and less buggy by 1) packaging code into functions and 2) adding them to a companion `R` file. Load your functions with `source()` in the same block you load your libraries with a relative path, full path, or ideally with `here()`.\n",
      "\n",
      "``` r\n",
      "library(here)\n",
      "source(here(\"R\", \"02MoniterGapJunction.R\")) #here's output is effectively ../R/02MoniterGapJunction.R\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(posts[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d287f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723119d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "92c2b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for json_entry in entries:\n",
    "\n",
    "    ts, name, text, files = parse_entry(entry=json_entry)\n",
    "\n",
    "    quarto_text = '\\n'.join([\n",
    "    '---',\n",
    "    f'title: \"Placeholder\"',\n",
    "    f'author: \"{name}\"',\n",
    "    f'date: \"{ts}\"',\n",
    "    'image: \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Alphabet_%281880%29_p.41.jpg\"',\n",
    "    'categories: ',\n",
    "    '  - code',\n",
    "    '  - beginner',\n",
    "    '  - r',\n",
    "    'draft: false',\n",
    "    'editor: ',\n",
    "    '  markdown: ',\n",
    "    '    wrap: 72',\n",
    "    '---',\n",
    "    '',\n",
    "    text,\n",
    "    '', \n",
    "    (lambda x: '' if x == [] else '\\n'.join(x))(files)\n",
    "    ])\n",
    "\n",
    "    # os.listdir('./')\n",
    "    # print(quarto_text)\n",
    "\n",
    "\n",
    "    dir_name = ts.replace('-', '')+'_Placeholder'\n",
    "\n",
    "    mkdir(path = './output/')\n",
    "    mkdir(path = f'./output/{dir_name}')\n",
    "\n",
    "    files_to_mv = [re.findall('\\(.*\\)', e)[0].replace('(', '').replace(')', '') for e in files]\n",
    "    if files_to_mv != []:\n",
    "        for e in files_to_mv:\n",
    "            if os.path.exists(loc_assets+e):\n",
    "                shutil.copy(\n",
    "                    loc_assets+e, \n",
    "                    f'./output/{dir_name}/{e}')\n",
    "        \n",
    "    with open(f'./output/{dir_name}/index.qmd', 'w') as f:\n",
    "        f.write(quarto_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "540ebfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab25a11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "22eea1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebdb212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b29f237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./better_code_assets/'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_assets\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loc_assets+'temp.qmd', 'w') as f:\n",
    "    f.write(write_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
